import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
from plotly.subplots import make_subplots
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest, RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import silhouette_score, r2_score, mean_squared_error, accuracy_score, classification_report
from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso
from sklearn.svm import SVR, SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.neural_network import MLPRegressor, MLPClassifier
from scipy import stats
from datetime import datetime, timedelta
import warnings
import io
from itertools import combinations

warnings.filterwarnings('ignore')

pd.set_option("styler.render.max_elements", 1000000)

st.set_page_config(
    page_title="æ•°æ®åˆ†æå¹³å°",
    page_icon="ğŸ§",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .stApp { background-color: #ffffff; }
    [data-testid="stSidebar"] { background-color: #f0f9ff; border-right: 1px solid #e0f2fe; }
    .section-title { font-size: 1.3rem; font-weight: 600; color: #0369a1; margin: 1.5rem 0 1rem 0; padding-bottom: 0.5rem; border-bottom: 2px solid #bae6fd; }
    .metric-card { background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%); border: 1px solid #bae6fd; border-radius: 8px; padding: 1rem; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    .metric-value { font-size: 1.5rem; font-weight: 600; color: #0c4a6e; }
    .metric-label { font-size: 0.8rem; color: #64748b; }
    .value-up { color: #dc2626; font-weight: 600; }
    .value-down { color: #16a34a; font-weight: 600; }
    .stButton>button { background-color: #bae6fd; color: #0369a1; border: 1px solid #7dd3fc; border-radius: 6px; padding: 0.5rem 1rem; font-weight: 500; transition: all 0.3s; }
    .stButton>button:hover { background-color: #7dd3fc; transform: translateY(-1px); box-shadow: 0 2px 8px rgba(125, 211, 252, 0.4); }
    .stButton>button[kind="primary"] { background: linear-gradient(135deg, #fbcfe8 0%, #f9a8d4 100%); color: #be185d; border: 1px solid #f9a8d4; }
    .stButton>button[kind="primary"]:hover { background: linear-gradient(135deg, #f9a8d4 0%, #f472b6 100%); }
    .stTabs [data-baseweb="tab-list"] { gap: 4px; background: #f8fafc; padding: 4px; border-radius: 8px; }
    .stTabs [data-baseweb="tab"] { background: transparent; border-radius: 6px; padding: 8px 16px; color: #64748b; transition: all 0.3s; }
    .stTabs [aria-selected="true"] { background-color: #bae6fd !important; color: #0369a1 !important; font-weight: 600; }
    .dataframe { border: 1px solid #e2e8f0 !important; border-radius: 8px !important; }
    th { background-color: #f0f9ff !important; color: #0369a1 !important; font-weight: 600 !important; border-bottom: 2px solid #bae6fd !important; padding: 10px !important; }
    td { border-bottom: 1px solid #f1f5f9 !important; padding: 8px !important; }
    hr { border: none; height: 1px; background: linear-gradient(90deg, transparent, #e2e8f0, transparent); margin: 1.5rem 0; }
    .algorithm-card { background: linear-gradient(135deg, #fdf2f8 0%, #fce7f3 100%); border: 1px solid #fbcfe8; border-radius: 8px; padding: 1rem; margin: 0.5rem 0; border-left: 4px solid #f472b6; }
    .algorithm-title { font-weight: 600; color: #be185d; margin-bottom: 0.5rem; }
    .info-box { background: #f0f9ff; border-left: 4px solid #0ea5e9; padding: 1rem; border-radius: 0 8px 8px 0; margin: 1rem 0; }
    .warning-box { background: #fffbeb; border-left: 4px solid #f59e0b; padding: 1rem; border-radius: 0 8px 8px 0; margin: 1rem 0; }
    .success-box { background: #f0fdf4; border-left: 4px solid #10b981; padding: 1rem; border-radius: 0 8px 8px 0; margin: 1rem 0; }
    .dim-tag { display: inline-block; background: #e0f2fe; color: #0369a1; padding: 2px 8px; border-radius: 12px; font-size: 0.75rem; margin: 2px; }
    .metric-tag { display: inline-block; background: #fce7f3; color: #be185d; padding: 2px 8px; border-radius: 12px; font-size: 0.75rem; margin: 2px; }
    .small-note { font-size: 0.75rem; color: #64748b; font-style: italic; }
    .field-container { max-height: 100px; overflow-y: auto; }
    .data-summary { font-size: 0.9rem; color: #475569; }
    .data-summary-value { font-size: 1.1rem; font-weight: 600; color: #0369a1; }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data(file_bytes, file_name):
    try:
        if file_name.endswith('.csv'):
            return pd.read_csv(io.BytesIO(file_bytes), encoding='utf-8')
        else:
            return pd.read_excel(io.BytesIO(file_bytes))
    except Exception as e:
        st.error(f"åŠ è½½å¤±è´¥: {e}")
        return None

def init_session_state():
    defaults = {
        'df': None, 'df_original': None, 'file_name': None,
        'date_columns': [], 'numeric_columns': [], 'categorical_columns': [],
        'data_loaded': False, 'current_module': 'æ•°æ®æ¦‚è§ˆ',
        'base_start': None, 'base_end': None, 'target_start': None, 'target_end': None
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def smart_format(val):
    if pd.isna(val) or val is None:
        return "-"
    try:
        num = float(val)
        if abs(num) >= 1000:
            return f"{num:,.0f}"
        elif abs(num) >= 100:
            return f"{num:,.1f}"
        elif abs(num) >= 1:
            return f"{num:,.2f}"
        else:
            return f"{num:,.4f}"
    except:
        return str(val)

def detect_column_types(df):
    date_cols, numeric_cols, cat_cols = [], [], []
    df = df.copy()
    
    for col in df.columns:
        if col.lower() in ['id', 'index', 'åºå·', 'ç¼–å·']:
            continue
            
        date_keywords = ['date', 'time', 'æ—¥æœŸ', 'æ—¶é—´', 'dt', 'day', 'month', 'year']
        col_lower = col.lower()
        has_date_keyword = any(kw in col_lower for kw in date_keywords)
        
        try:
            threshold = 0.5 if has_date_keyword else 0.9
            converted = pd.to_datetime(df[col].astype(str), errors='coerce')
            if converted.notna().sum() / len(df) > threshold and converted.nunique() > 1:
                date_cols.append(col)
                df[col] = converted
                continue
        except:
            pass
        
        if pd.api.types.is_numeric_dtype(df[col]):
            unique_ratio = df[col].nunique() / len(df)
            if df[col].nunique() < 10 and unique_ratio < 0.05:
                cat_cols.append(col)
            else:
                numeric_cols.append(col)
        else:
            try:
                converted = pd.to_numeric(df[col].astype(str).str.replace(',', '').str.replace('%', ''), errors='coerce')
                if converted.notna().sum() / len(df) > 0.8:
                    df[col] = converted
                    unique_ratio = df[col].nunique() / len(df)
                    if df[col].nunique() < 10 and unique_ratio < 0.05:
                        cat_cols.append(col)
                    else:
                        numeric_cols.append(col)
                else:
                    cat_cols.append(col)
            except:
                cat_cols.append(col)
    
    return df, date_cols, numeric_cols, cat_cols

def render_time_range_selector(df, date_col):
    if date_col not in df.columns:
        return None, None, None, None
    
    dates = pd.to_datetime(df[date_col].dropna()).sort_values().unique()
    if len(dates) < 2:
        st.warning("æ—¥æœŸæ•°æ®ä¸è¶³")
        return None, None, None, None
    
    default_target_date = dates[-1]
    default_base_date = dates[-2] if len(dates) >= 2 else dates[-1]
    
    quick_options = st.radio("å¿«æ·é€‰æ‹©", 
                            ["è‡ªå®šä¹‰", "å•æ—¥å¯¹æ¯”ï¼ˆæ˜¨ vs ä»Šï¼‰", "æœ€è¿‘7å¤© vs å‰7å¤©", "æœ€è¿‘30å¤© vs å‰30å¤©"], 
                            horizontal=True)
    
    if quick_options == "å•æ—¥å¯¹æ¯”ï¼ˆæ˜¨ vs ä»Šï¼‰":
        return (default_base_date.strftime('%Y-%m-%d'), default_base_date.strftime('%Y-%m-%d'),
                default_target_date.strftime('%Y-%m-%d'), default_target_date.strftime('%Y-%m-%d'))
    
    elif quick_options == "æœ€è¿‘7å¤© vs å‰7å¤©":
        if len(dates) >= 14:
            base_end = dates[-8]
            base_start = dates[-14]
            target_start = dates[-7]
            target_end = dates[-1]
            return (base_start.strftime('%Y-%m-%d'), base_end.strftime('%Y-%m-%d'),
                    target_start.strftime('%Y-%m-%d'), target_end.strftime('%Y-%m-%d'))
        else:
            st.warning("æ•°æ®ä¸è¶³14å¤©ï¼Œä½¿ç”¨å•æ—¥å¯¹æ¯”")
            return (default_base_date.strftime('%Y-%m-%d'), default_base_date.strftime('%Y-%m-%d'),
                    default_target_date.strftime('%Y-%m-%d'), default_target_date.strftime('%Y-%m-%d'))
    
    elif quick_options == "æœ€è¿‘30å¤© vs å‰30å¤©":
        if len(dates) >= 60:
            base_end = dates[-31]
            base_start = dates[-60]
            target_start = dates[-30]
            target_end = dates[-1]
            return (base_start.strftime('%Y-%m-%d'), base_end.strftime('%Y-%m-%d'),
                    target_start.strftime('%Y-%m-%d'), target_end.strftime('%Y-%m-%d'))
        else:
            st.warning("æ•°æ®ä¸è¶³60å¤©ï¼Œä½¿ç”¨å•æ—¥å¯¹æ¯”")
            return (default_base_date.strftime('%Y-%m-%d'), default_base_date.strftime('%Y-%m-%d'),
                    default_target_date.strftime('%Y-%m-%d'), default_target_date.strftime('%Y-%m-%d'))
    
    st.markdown("**åŸºæœŸï¼ˆå¯¹æ¯”æœŸï¼‰**")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        base_year = st.selectbox("å¹´", sorted(set(pd.to_datetime(dates).year), reverse=True), 
                                index=0, key="base_year")
    with col2:
        base_months = sorted(set([d.month for d in dates if d.year == base_year]), reverse=True)
        base_month = st.selectbox("æœˆ", base_months, index=0, key="base_month")
    with col3:
        month_dates = [d for d in dates if d.year == base_year and d.month == base_month]
        base_start = st.selectbox("å¼€å§‹æ—¥", [d.strftime('%Y-%m-%d') for d in month_dates], 
                                 index=len(month_dates)-1 if month_dates else 0, key="base_start")
    with col4:
        base_end = st.selectbox("ç»“æŸæ—¥", [d.strftime('%Y-%m-%d') for d in month_dates], 
                               index=len(month_dates)-1 if month_dates else 0, key="base_end")
    
    st.markdown("**ç›®æ ‡æœŸï¼ˆåˆ†ææœŸï¼‰**")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        target_year = st.selectbox("å¹´", sorted(set(pd.to_datetime(dates).year), reverse=True), 
                                  index=0, key="target_year")
    with col2:
        target_months = sorted(set([d.month for d in dates if d.year == target_year]), reverse=True)
        target_month = st.selectbox("æœˆ", target_months, index=0, key="target_month")
    with col3:
        month_dates_target = [d for d in dates if d.year == target_year and d.month == target_month]
        target_start = st.selectbox("å¼€å§‹æ—¥", [d.strftime('%Y-%m-%d') for d in month_dates_target], 
                                   index=len(month_dates_target)-1 if month_dates_target else 0, key="target_start")
    with col4:
        target_end = st.selectbox("ç»“æŸæ—¥", [d.strftime('%Y-%m-%d') for d in month_dates_target], 
                                 index=len(month_dates_target)-1 if month_dates_target else 0, key="target_end")
    
    return base_start, base_end, target_start, target_end

class AttributionEngine:
    @staticmethod
    def calculate_contribution(df, dimension, metric, date_col, base_start, base_end, target_start, target_end):
        try:
            base_start_dt = pd.to_datetime(base_start)
            base_end_dt = pd.to_datetime(base_end)
            target_start_dt = pd.to_datetime(target_start)
            target_end_dt = pd.to_datetime(target_end)
            df[date_col] = pd.to_datetime(df[date_col])
            
            base_df = df[(df[date_col] >= base_start_dt) & (df[date_col] <= base_end_dt)]
            target_df = df[(df[date_col] >= target_start_dt) & (df[date_col] <= target_end_dt)]
            
            base_data = base_df.groupby(dimension)[metric].sum()
            target_data = target_df.groupby(dimension)[metric].sum()
            
            all_dims = sorted(list(set(base_data.index) | set(target_data.index)))
            
            total_base = base_data.sum()
            total_target = target_data.sum()
            total_change = total_target - total_base
            total_change_rate = (total_change / total_base * 100) if total_base != 0 else 0
            
            results = []
            for dim in all_dims:
                base_val = base_data.get(dim, 0)
                target_val = target_data.get(dim, 0)
                change = target_val - base_val
                
                if base_val != 0:
                    change_rate = (change / base_val) * 100
                else:
                    change_rate = 0
                
                if total_change != 0:
                    contribution_pct = (change / total_change) * 100
                else:
                    contribution_pct = 0
                
                contribution_pp = contribution_pct * total_change_rate / 100
                
                results.append({
                    'ç»´åº¦': dimension,
                    'ç»´åº¦å€¼': dim,
                    'åŸºæœŸå€¼': base_val,
                    'ç›®æ ‡æœŸå€¼': target_val,
                    'å˜åŠ¨': change,
                    'å˜åŠ¨ç‡': change_rate,
                    'è´¡çŒ®ç™¾åˆ†æ¯”': contribution_pct,
                    'è´¡çŒ®pp': contribution_pp
                })
            
            result_df = pd.DataFrame(results).sort_values('å˜åŠ¨', key=abs, ascending=False)
            
            total_row = pd.DataFrame([{
                'ç»´åº¦': dimension,
                'ç»´åº¦å€¼': 'ã€æ€»è®¡ã€‘',
                'åŸºæœŸå€¼': total_base,
                'ç›®æ ‡æœŸå€¼': total_target,
                'å˜åŠ¨': total_change,
                'å˜åŠ¨ç‡': total_change_rate,
                'è´¡çŒ®ç™¾åˆ†æ¯”': 100.0,
                'è´¡çŒ®pp': total_change_rate
            }])
            result_df = pd.concat([total_row, result_df], ignore_index=True)
            
            return result_df, total_change, total_base, total_target, total_change_rate
        except Exception as e:
            st.error(f"å½’å› è®¡ç®—é”™è¯¯: {str(e)}")
            return None, 0, 0, 0, 0

    @staticmethod
    def multi_dim_analysis(df, dims, metric, date_col, base_start, base_end, target_start, target_end):
        try:
            base_start_dt = pd.to_datetime(base_start)
            base_end_dt = pd.to_datetime(base_end)
            target_start_dt = pd.to_datetime(target_start)
            target_end_dt = pd.to_datetime(target_end)
            df[date_col] = pd.to_datetime(df[date_col])
            
            base_df = df[(df[date_col] >= base_start_dt) & (df[date_col] <= base_end_dt)]
            target_df = df[(df[date_col] >= target_start_dt) & (df[date_col] <= target_end_dt)]
            
            base_data = base_df.groupby(dims)[metric].sum().reset_index()
            target_data = target_df.groupby(dims)[metric].sum().reset_index()
            
            merged = pd.merge(base_data, target_data, on=dims, how='outer', suffixes=('_åŸºæœŸ', '_ç›®æ ‡æœŸ')).fillna(0)
            merged['å˜åŠ¨'] = merged[f'{metric}_ç›®æ ‡æœŸ'] - merged[f'{metric}_åŸºæœŸ']
            
            total_base = merged[f'{metric}_åŸºæœŸ'].sum()
            total_target = merged[f'{metric}_ç›®æ ‡æœŸ'].sum()
            total_change = total_target - total_base
            
            merged['å˜åŠ¨ç‡'] = np.where(merged[f'{metric}_åŸºæœŸ'] != 0, 
                                     (merged['å˜åŠ¨'] / merged[f'{metric}_åŸºæœŸ']) * 100, 0)
            merged['è´¡çŒ®ç™¾åˆ†æ¯”'] = np.where(total_change != 0, (merged['å˜åŠ¨'] / total_change) * 100, 0)
            
            total_change_rate = (total_change / total_base * 100) if total_base != 0 else 0
            merged['è´¡çŒ®pp'] = merged['è´¡çŒ®ç™¾åˆ†æ¯”'] * total_change_rate / 100
            
            merged = merged.rename(columns={
                f'{metric}_åŸºæœŸ': 'åŸºæœŸå€¼',
                f'{metric}_ç›®æ ‡æœŸ': 'ç›®æ ‡æœŸå€¼'
            })
            
            if len(dims) > 2:
                merged['ç»„åˆç»´åº¦'] = merged[dims].astype(str).agg(' | '.join, axis=1)
            
            result_cols = dims + ['åŸºæœŸå€¼', 'ç›®æ ‡æœŸå€¼', 'å˜åŠ¨', 'å˜åŠ¨ç‡', 'è´¡çŒ®ç™¾åˆ†æ¯”', 'è´¡çŒ®pp']
            if len(dims) > 2:
                result_cols.append('ç»„åˆç»´åº¦')
            
            merged = merged[result_cols].sort_values('å˜åŠ¨', key=abs, ascending=False)
            
            total_row_data = {dim: 'ã€æ€»è®¡ã€‘' for dim in dims}
            if len(dims) > 2:
                total_row_data['ç»„åˆç»´åº¦'] = 'ã€æ€»è®¡ã€‘'
            total_row_data.update({
                'åŸºæœŸå€¼': total_base,
                'ç›®æ ‡æœŸå€¼': total_target,
                'å˜åŠ¨': total_change,
                'å˜åŠ¨ç‡': total_change_rate,
                'è´¡çŒ®ç™¾åˆ†æ¯”': 100.0,
                'è´¡çŒ®pp': total_change_rate
            })
            total_row = pd.DataFrame([total_row_data])
            merged = pd.concat([total_row, merged], ignore_index=True)
            
            return merged, total_change, total_base, total_target
        except Exception as e:
            st.error(f"å¤šç»´åº¦åˆ†æå¤±è´¥: {str(e)}")
            return None, 0, 0, 0

ML_ALGORITHMS = {
    "èšç±»åˆ†æ": {
        "KMeans": {"name": "K-Meansèšç±»", "desc": "åŸºäºè·ç¦»çš„è¿­ä»£èšç±»ï¼Œé€‚åˆçƒå½¢åˆ†å¸ƒæ•°æ®ã€‚éœ€æŒ‡å®šç°‡æ•°é‡ã€‚", "params": {"n_clusters": (2, 10, 3)}},
        "DBSCAN": {"name": "DBSCANå¯†åº¦èšç±»", "desc": "åŸºäºå¯†åº¦çš„ç©ºé—´èšç±»ï¼Œè‡ªåŠ¨è¯†åˆ«å™ªå£°ç‚¹ï¼Œé€‚åˆä¸è§„åˆ™å½¢çŠ¶ã€‚", "params": {"eps": (0.1, 2.0, 0.5), "min_samples": (2, 10, 5)}},
        "Hierarchical": {"name": "å±‚æ¬¡èšç±»", "desc": "æ„å»ºæ ‘çŠ¶èšç±»ç»“æ„ï¼Œæ— éœ€é¢„è®¾ç°‡æ•°é‡ï¼Œé€‚åˆå‘ç°å±‚æ¬¡å…³ç³»ã€‚", "params": {"n_clusters": (2, 10, 3), "linkage": ["ward", "complete", "average"]}}
    },
    "å¼‚å¸¸æ£€æµ‹": {
        "IsolationForest": {"name": "å­¤ç«‹æ£®æ—", "desc": "åŸºäºéšæœºåˆ’åˆ†çš„å¼‚å¸¸æ£€æµ‹ï¼Œå¯¹é«˜ç»´æ•°æ®æ•ˆæœå¥½ã€‚", "params": {"contamination": (0.01, 0.3, 0.05)}},
        "ZScore": {"name": "Z-Scoreç»Ÿè®¡", "desc": "åŸºäºæ ‡å‡†å·®çš„ç»Ÿè®¡æ–¹æ³•ï¼Œè¯†åˆ«åç¦»å‡å€¼3å€æ ‡å‡†å·®çš„å¼‚å¸¸ã€‚", "params": {"threshold": (2, 4, 3)}}
    },
    "å›å½’åˆ†æ": {
        "LinearRegression": {"name": "çº¿æ€§å›å½’", "desc": "åŸºç¡€çš„çº¿æ€§å…³ç³»å»ºæ¨¡ï¼Œç®€å•å¯è§£é‡Šã€‚", "params": {}},
        "Ridge": {"name": "å²­å›å½’(L2)", "desc": "æ·»åŠ L2æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œé€‚åˆå¤šé‡å…±çº¿æ€§æ•°æ®ã€‚", "params": {"alpha": (0.01, 10.0, 1.0)}},
        "RandomForestRegressor": {"name": "éšæœºæ£®æ—å›å½’", "desc": "é›†æˆå¤šä¸ªå†³ç­–æ ‘ï¼Œå¤„ç†éçº¿æ€§å…³ç³»ï¼Œå‡†ç¡®åº¦é«˜ã€‚", "params": {"n_estimators": (50, 300, 100), "max_depth": (3, 20, 10)}},
        "GradientBoosting": {"name": "æ¢¯åº¦æå‡å›å½’", "desc": "ä¸²è¡Œé›†æˆå­¦ä¹ ï¼Œç²¾åº¦é«˜ï¼Œé€‚åˆç«èµ›åœºæ™¯ã€‚", "params": {"n_estimators": (50, 300, 100), "learning_rate": (0.01, 0.3, 0.1)}},
        "SVR": {"name": "æ”¯æŒå‘é‡å›å½’", "desc": "é€‚åˆéçº¿æ€§å›å½’ï¼Œé€šè¿‡æ ¸å‡½æ•°æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ã€‚", "params": {"kernel": ["rbf", "linear", "poly"], "C": (0.1, 10.0, 1.0)}},
        "MLPRegressor": {"name": "ç¥ç»ç½‘ç»œå›å½’", "desc": "å¤šå±‚æ„ŸçŸ¥å™¨ï¼Œé€‚åˆå¤æ‚éçº¿æ€§æ˜ å°„ã€‚", "params": {"hidden_layer_sizes": [(50,), (100,), (50,50)], "max_iter": (500, 2000, 1000)}}
    },
    "åˆ†ç±»åˆ†æ": {
        "LogisticRegression": {"name": "é€»è¾‘å›å½’", "desc": "äºŒåˆ†ç±»åŸºç¡€æ¨¡å‹ï¼Œè¾“å‡ºæ¦‚ç‡ï¼Œå¯è§£é‡Šæ€§å¼ºã€‚", "params": {"C": (0.1, 10.0, 1.0)}},
        "RandomForestClassifier": {"name": "éšæœºæ£®æ—åˆ†ç±»", "desc": "é›†æˆå†³ç­–æ ‘ï¼Œå¤„ç†ç‰¹å¾é—´å¤æ‚äº¤äº’ã€‚", "params": {"n_estimators": (50, 300, 100)}},
        "SVC": {"name": "æ”¯æŒå‘é‡æœº", "desc": "é€‚åˆé«˜ç»´æ•°æ®ï¼Œé€šè¿‡æ ¸æŠ€å·§å¤„ç†éçº¿æ€§ã€‚", "params": {"kernel": ["rbf", "linear"], "C": (0.1, 10.0, 1.0)}},
        "KNN": {"name": "Kè¿‘é‚»", "desc": "åŸºäºç›¸ä¼¼åº¦çš„æƒ°æ€§å­¦ä¹ ï¼Œæ— éœ€è®­ç»ƒè¿‡ç¨‹ã€‚", "params": {"n_neighbors": (3, 15, 5)}},
        "DecisionTree": {"name": "å†³ç­–æ ‘", "desc": "æ ‘çŠ¶è§„åˆ™ï¼Œæœ€æ˜“è§£é‡Šï¼Œå¯å¯è§†åŒ–å†³ç­–è·¯å¾„ã€‚", "params": {"max_depth": (3, 20, 5)}},
        "NaiveBayes": {"name": "æœ´ç´ è´å¶æ–¯", "desc": "åŸºäºæ¦‚ç‡çš„åˆ†ç±»ï¼Œå‡è®¾ç‰¹å¾ç‹¬ç«‹ï¼Œé€Ÿåº¦å¿«ã€‚", "params": {}},
        "MLPClassifier": {"name": "ç¥ç»ç½‘ç»œåˆ†ç±»", "desc": "å¤šå±‚æ„ŸçŸ¥å™¨åˆ†ç±»å™¨ï¼Œé€‚åˆå¤æ‚è¾¹ç•Œã€‚", "params": {"hidden_layer_sizes": [(50,), (100,)], "max_iter": (500, 2000, 1000)}}
    },
    "é™ç»´åˆ†æ": {
        "PCA": {"name": "ä¸»æˆåˆ†åˆ†æ(PCA)", "desc": "çº¿æ€§é™ç»´ï¼Œä¿ç•™æœ€å¤§æ–¹å·®æ–¹å‘ï¼Œå»ç›¸å…³æ€§ã€‚", "params": {"n_components": (2, 10, 2)}},
        "FeatureImportance": {"name": "ç‰¹å¾é‡è¦æ€§", "desc": "ä½¿ç”¨éšæœºæ£®æ—è¯„ä¼°ç‰¹å¾å¯¹ç›®æ ‡çš„è´¡çŒ®åº¦ã€‚", "params": {"n_estimators": (50, 300, 100)}}
    }
}

class AdvancedMLModule:
    def __init__(self, df):
        self.df = df
        self.scaler = StandardScaler()
    
    def clustering(self, features, algorithm, params):
        try:
            X = self.df[features].dropna()
            if len(X) < 3:
                return None, None, 0, None
            
            X_scaled = self.scaler.fit_transform(X)
            
            if algorithm == "KMeans":
                model = KMeans(n_clusters=params['n_clusters'], random_state=42, n_init=10)
                labels = model.fit_predict(X_scaled)
            elif algorithm == "DBSCAN":
                model = DBSCAN(eps=params['eps'], min_samples=int(params['min_samples']))
                labels = model.fit_predict(X_scaled)
            elif algorithm == "Hierarchical":
                model = AgglomerativeClustering(n_clusters=params['n_clusters'], linkage=params['linkage'])
                labels = model.fit_predict(X_scaled)
            
            X_display = X.copy()
            X_display['èšç±»'] = labels
            
            mask = labels != -1
            if len(set(labels[mask])) > 1 and mask.sum() > 1:
                score = silhouette_score(X_scaled[mask], labels[mask])
            else:
                score = 0
            
            if len(features) >= 2:
                fig = px.scatter(X_display, x=features[0], y=features[1], color='èšç±»', 
                               title=f"{algorithm} èšç±»ç»“æœ", color_continuous_scale=px.colors.qualitative.Set1)
            else:
                fig = px.histogram(X_display, x=features[0], color='èšç±»', 
                                 title=f"{algorithm} èšç±»åˆ†å¸ƒ")
            fig.update_layout(height=500)
            
            stats = X_display.groupby('èšç±»')[features].agg(['mean', 'std', 'count']).round(2)
            
            return fig, stats, score, X_display
        except Exception as e:
            st.error(f"èšç±»å¤±è´¥: {str(e)}")
            return None, None, 0, None

    def anomaly_detection(self, features, algorithm, params):
        try:
            X = self.df[features].dropna()
            if len(X) < 10:
                return None, 0, None
            
            if algorithm == "IsolationForest":
                model = IsolationForest(contamination=params['contamination'], random_state=42)
                y_pred = model.fit_predict(X)
                scores = model.decision_function(X)
            elif algorithm == "ZScore":
                z_scores = np.abs(stats.zscore(X))
                y_pred = np.where((z_scores > params['threshold']).any(axis=1), -1, 1)
                scores = -z_scores.max(axis=1)
            
            X_display = X.copy()
            X_display['ç±»å‹'] = ['å¼‚å¸¸' if x == -1 else 'æ­£å¸¸' for x in y_pred]
            X_display['å¼‚å¸¸åˆ†æ•°'] = scores
            
            if len(features) >= 2:
                fig = px.scatter(X_display, x=features[0], y=features[1], color='ç±»å‹', 
                               color_discrete_map={'æ­£å¸¸': '#0369a1', 'å¼‚å¸¸': '#dc2626'},
                               title="å¼‚å¸¸æ£€æµ‹å¯è§†åŒ–", size='å¼‚å¸¸åˆ†æ•°' if algorithm == 'IsolationForest' else None)
            else:
                fig = px.histogram(X_display, x=features[0], color='ç±»å‹',
                                 color_discrete_map={'æ­£å¸¸': '#0369a1', 'å¼‚å¸¸': '#dc2626'},
                                 title="å¼‚å¸¸æ£€æµ‹åˆ†å¸ƒ")
            fig.update_layout(height=500)
            
            anomaly_count = (y_pred == -1).sum()
            
            return fig, anomaly_count, X_display[['ç±»å‹', 'å¼‚å¸¸åˆ†æ•°'] + features]
        except Exception as e:
            st.error(f"å¼‚å¸¸æ£€æµ‹å¤±è´¥: {str(e)}")
            return None, 0, None

    def regression(self, target, features, algorithm, params, test_size=0.2):
        try:
            df_clean = self.df[features + [target]].dropna()
            if len(df_clean) < 20:
                return None, 0, 0, None, None
            
            X = df_clean[features]
            y = df_clean[target]
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            if algorithm == "LinearRegression":
                model = LinearRegression()
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            elif algorithm == "Ridge":
                model = Ridge(alpha=params['alpha'])
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            elif algorithm == "RandomForestRegressor":
                model = RandomForestRegressor(n_estimators=int(params['n_estimators']), 
                                            max_depth=int(params['max_depth']), random_state=42)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            elif algorithm == "GradientBoosting":
                model = GradientBoostingRegressor(n_estimators=int(params['n_estimators']), 
                                                learning_rate=params['learning_rate'], random_state=42)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            elif algorithm == "SVR":
                model = SVR(kernel=params['kernel'], C=params['C'])
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            elif algorithm == "MLPRegressor":
                model = MLPRegressor(hidden_layer_sizes=params['hidden_layer_sizes'], 
                                   max_iter=int(params['max_iter']), random_state=42)
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            
            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            mae = np.mean(np.abs(y_test - y_pred))
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=y_test, y=y_pred, mode='markers', name='é¢„æµ‹å€¼',
                                   marker=dict(color='#0ea5e9', size=8)))
            fig.add_trace(go.Scatter(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], 
                                   mode='lines', name='ç†æƒ³çº¿', line=dict(color='#dc2626', dash='dash')))
            fig.update_layout(title=f"{algorithm} å›å½’æ•ˆæœ (RÂ²={r2:.3f})", 
                            xaxis_title="å®é™…å€¼", yaxis_title="é¢„æµ‹å€¼", height=500)
            
            importance = None
            if hasattr(model, 'feature_importances_'):
                importance = pd.DataFrame({
                    'ç‰¹å¾': features,
                    'é‡è¦æ€§': model.feature_importances_
                }).sort_values('é‡è¦æ€§', ascending=False)
            elif hasattr(model, 'coef_'):
                importance = pd.DataFrame({
                    'ç‰¹å¾': features,
                    'ç³»æ•°': model.coef_
                }).sort_values('ç³»æ•°', key=abs, ascending=False)
            
            return fig, r2, rmse, importance, {
                'MAE': mae, 'RMSE': rmse, 'RÂ²': r2, 
                'æ ·æœ¬æ•°': len(df_clean), 'è®­ç»ƒé›†': len(X_train), 'æµ‹è¯•é›†': len(X_test)
            }
        except Exception as e:
            st.error(f"å›å½’åˆ†æå¤±è´¥: {str(e)}")
            return None, 0, 0, None, None

    def classification(self, target, features, algorithm, params, test_size=0.2):
        try:
            df_clean = self.df[features + [target]].dropna()
            if len(df_clean) < 20:
                return None, 0, None, None
            
            X = df_clean[features]
            y = df_clean[target]
            
            if y.dtype in ['float64', 'int64'] and y.nunique() > 5:
                median = y.median()
                y = (y > median).astype(int)
                st.info(f"ç›®æ ‡å˜é‡å·²è‡ªåŠ¨äºŒå€¼åŒ–ï¼ˆä¸­ä½æ•°åˆ†å‰²: {median:.2f}ï¼‰")
            
            if y.nunique() < 2:
                st.error("ç›®æ ‡å˜é‡ç±»åˆ«æ•°ä¸è¶³")
                return None, 0, None, None
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            if algorithm == "LogisticRegression":
                model = LogisticRegression(C=params['C'], max_iter=1000)
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            elif algorithm == "RandomForestClassifier":
                model = RandomForestClassifier(n_estimators=int(params['n_estimators']), random_state=42)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            elif algorithm == "SVC":
                model = SVC(kernel=params['kernel'], C=params['C'], probability=True)
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            elif algorithm == "KNN":
                model = KNeighborsClassifier(n_neighbors=int(params['n_neighbors']))
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            elif algorithm == "DecisionTree":
                model = DecisionTreeClassifier(max_depth=int(params['max_depth']), random_state=42)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            elif algorithm == "NaiveBayes":
                model = GaussianNB()
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            elif algorithm == "MLPClassifier":
                model = MLPClassifier(hidden_layer_sizes=params['hidden_layer_sizes'], 
                                    max_iter=int(params['max_iter']), random_state=42)
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            
            acc = accuracy_score(y_test, y_pred)
            report = classification_report(y_test, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(y_test, y_pred)
            fig = ff.create_annotated_heatmap(cm, x=[f'é¢„æµ‹{i}' for i in sorted(y.unique())], 
                                            y=[f'å®é™…{i}' for i in sorted(y.unique())],
                                            colorscale='Blues', showscale=True)
            fig.update_layout(title=f"{algorithm} æ··æ·†çŸ©é˜µ (å‡†ç¡®ç‡: {acc:.2%})")
            
            importance = None
            if hasattr(model, 'feature_importances_'):
                importance = pd.DataFrame({
                    'ç‰¹å¾': features,
                    'é‡è¦æ€§': model.feature_importances_
                }).sort_values('é‡è¦æ€§', ascending=False)
            elif hasattr(model, 'coef_'):
                importance = pd.DataFrame({
                    'ç‰¹å¾': features,
                    'ç³»æ•°': model.coef_[0] if len(model.coef_.shape) > 1 else model.coef_
                }).sort_values('ç³»æ•°', key=abs, ascending=False)
            
            return fig, acc, report_df, importance, len(y.unique())
        except Exception as e:
            st.error(f"åˆ†ç±»åˆ†æå¤±è´¥: {str(e)}")
            return None, 0, None, None, 0

    def dimension_reduction(self, features, algorithm, params, target=None):
        try:
            X = self.df[features].dropna()
            if len(X) < 10:
                return None, None, 0, None
            
            X_scaled = self.scaler.fit_transform(X)
            
            if algorithm == "PCA":
                n_comp = min(int(params['n_components']), len(features), len(X))
                model = PCA(n_components=n_comp)
                X_reduced = model.fit_transform(X_scaled)
                
                variance_df = pd.DataFrame({
                    'ä¸»æˆåˆ†': [f'PC{i+1}' for i in range(n_comp)],
                    'è§£é‡Šæ–¹å·®æ¯”ä¾‹(%)': model.explained_variance_ratio_ * 100,
                    'ç´¯ç§¯è§£é‡Šæ–¹å·®(%)': np.cumsum(model.explained_variance_ratio_) * 100
                })
                
                if target and target in self.df.columns:
                    y = self.df.loc[X.index, target]
                    fig = px.scatter(x=X_reduced[:, 0], y=X_reduced[:, 1] if n_comp > 1 else np.zeros(len(X_reduced)), 
                                   color=y, title=f"PCAé™ç»´ç»“æœ ( colored by {target} )")
                else:
                    fig = px.scatter(x=X_reduced[:, 0], y=X_reduced[:, 1] if n_comp > 1 else np.zeros(len(X_reduced)),
                                   title="PCAé™ç»´ç»“æœ")
                fig.update_layout(height=500, xaxis_title='PC1', yaxis_title='PC2' if n_comp > 1 else '')
                
                loadings = pd.DataFrame(model.components_.T, columns=[f'PC{i+1}' for i in range(n_comp)], index=features)
                
                return fig, variance_df, model.explained_variance_ratio_.sum() * 100, loadings
                
            elif algorithm == "FeatureImportance":
                if target is None or target not in self.df.columns:
                    st.error("ç‰¹å¾é‡è¦æ€§éœ€è¦ç›®æ ‡å˜é‡")
                    return None, None, 0, None
                
                y = self.df.loc[X.index, target]
                model = RandomForestRegressor(n_estimators=int(params['n_estimators']), random_state=42)
                model.fit(X, y)
                
                importance = pd.DataFrame({
                    'ç‰¹å¾': features,
                    'é‡è¦æ€§': model.feature_importances_
                }).sort_values('é‡è¦æ€§', ascending=True)
                
                fig = px.bar(importance, x='é‡è¦æ€§', y='ç‰¹å¾', orientation='h', title="ç‰¹å¾é‡è¦æ€§æ’åº")
                fig.update_layout(height=500)
                
                return fig, importance, model.score(X, y), None
                
        except Exception as e:
            st.error(f"é™ç»´åˆ†æå¤±è´¥: {str(e)}")
            return None, None, 0, None

FORECAST_ALGORITHMS = {
    "Prophet": {
        "name": "Prophetæ—¶é—´åºåˆ—", 
        "desc": "Facebookå¼€å‘çš„åŠ æ³•å›å½’æ¨¡å‹ï¼Œè‡ªåŠ¨å¤„ç†è¶‹åŠ¿ã€å­£èŠ‚æ€§å’ŒèŠ‚å‡æ—¥ã€‚é€‚åˆæœ‰æ˜æ˜¾å‘¨æœŸæ€§çš„ä¸šåŠ¡æ•°æ®ã€‚",
        "best_for": "å…·æœ‰å¼ºå­£èŠ‚æ€§çš„ä¸šåŠ¡æŒ‡æ ‡",
        "complexity": "ä¸­"
    },
    "ARIMA": {
        "name": "ARIMAè‡ªå›å½’ç§¯åˆ†æ»‘åŠ¨å¹³å‡", 
        "desc": "ç»å…¸ç»Ÿè®¡æ–¹æ³•ï¼Œç»“åˆè‡ªå›å½’å’Œå·®åˆ†ã€‚é€‚åˆå¹³ç¨³æˆ–å·®åˆ†åå¹³ç¨³çš„æ—¶é—´åºåˆ—ã€‚",
        "best_for": "è¶‹åŠ¿æ€§è¾ƒå¼ºçš„éå­£èŠ‚æ€§æ•°æ®",
        "complexity": "ä¸­"
    },
    "ExponentialSmoothing": {
        "name": "æŒ‡æ•°å¹³æ»‘æ³•(Holt-Winters)", 
        "desc": "åŠ æƒå¹³å‡æ–¹æ³•ï¼Œè¿‘æœŸæ•°æ®æƒé‡æ›´é«˜ã€‚Holt-Winterså¢åŠ è¶‹åŠ¿å’Œå­£èŠ‚é¡¹ã€‚",
        "best_for": "çŸ­æœŸé¢„æµ‹ï¼Œå¹³æ»‘è¶‹åŠ¿æ•°æ®",
        "complexity": "ä½"
    },
    "RandomForest_TS": {
        "name": "éšæœºæ£®æ—(æ—¶é—´åºåˆ—ç‰¹å¾)", 
        "desc": "ä½¿ç”¨æ»åç‰¹å¾ã€æ»‘åŠ¨çª—å£ç­‰æ—¶åºç‰¹å¾å·¥ç¨‹çš„æœºå™¨å­¦ä¹ é¢„æµ‹ã€‚",
        "best_for": "å¤æ‚çš„éçº¿æ€§æ—¶é—´æ¨¡å¼",
        "complexity": "é«˜"
    },
    "XGBoost_TS": {
        "name": "XGBoostæ¢¯åº¦æå‡", 
        "desc": "æç«¯æ¢¯åº¦æå‡ï¼Œä½¿ç”¨å¼ºå¤§çš„æ—¶é—´ç‰¹å¾å·¥ç¨‹ï¼Œé€šå¸¸ç²¾åº¦æœ€é«˜ã€‚",
        "best_for": "å¤§æ•°æ®é‡ï¼Œå¤æ‚æ¨¡å¼è¯†åˆ«",
        "complexity": "é«˜"
    },
    "LSTM": {
        "name": "LSTMé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ", 
        "desc": "æ·±åº¦å­¦ä¹ å¾ªç¯ç¥ç»ç½‘ç»œï¼Œé€‚åˆæ•æ‰é•¿æœŸä¾èµ–å…³ç³»ã€‚",
        "best_for": "é•¿æœŸæ¨¡å¼ï¼Œå¤§æ•°æ®é‡",
        "complexity": "å¾ˆé«˜"
    }
}

class AdvancedForecastModule:
    def __init__(self, df):
        self.df = df
    
    def prepare_features(self, series, lags=7, window=7):
        """å‡†å¤‡æ—¶é—´åºåˆ—ç‰¹å¾ï¼Œå¢åŠ ç©ºå€¼æ£€æŸ¥"""
        if len(series) == 0:
            return pd.DataFrame()
            
        df_feat = pd.DataFrame({'y': series})
        df_feat['dayofweek'] = series.index.dayofweek
        df_feat['month'] = series.index.month
        df_feat['day'] = series.index.day
        df_feat['year'] = series.index.year
        
        for i in range(1, lags + 1):
            df_feat[f'lag_{i}'] = series.shift(i)
        
        df_feat[f'rolling_mean_{window}'] = series.rolling(window=window, min_periods=1).mean()
        df_feat[f'rolling_std_{window}'] = series.rolling(window=window, min_periods=1).std()
        df_feat[f'expanding_mean'] = series.expanding(min_periods=1).mean()
        
        df_feat['diff_1'] = series.diff(1)
        df_feat['diff_7'] = series.diff(7)
        
        return df_feat.dropna()
    
    def forecast(self, date_col, metric, algorithm, periods=30, freq='D'):
        try:
            ts_data = self.df.groupby(date_col)[metric].sum().reset_index()
            ts_data[date_col] = pd.to_datetime(ts_data[date_col])
            ts_data = ts_data.sort_values(date_col).set_index(date_col)
            
            if len(ts_data) == 0:
                st.error("æ—¶é—´åºåˆ—æ•°æ®ä¸ºç©º")
                return None, None
                
            ts_data = ts_data.asfreq(freq).fillna(method='ffill')
            
            if len(ts_data) < 30:
                st.warning("æ—¶é—´åºåˆ—æ•°æ®å°‘äº30å¤©ï¼Œå¯èƒ½å½±å“é¢„æµ‹ç²¾åº¦")
            
            # ç¡®ä¿è®­ç»ƒæ•°æ®è¶³å¤Ÿ
            if len(ts_data) <= periods:
                st.error(f"æ•°æ®é‡({len(ts_data)})ä¸è¶³ï¼Œéœ€è¦è‡³å°‘{periods+1}æ¡æ•°æ®æ‰èƒ½è¿›è¡Œé¢„æµ‹")
                return None, None
                
            train = ts_data.iloc[:-periods]
            
            if len(train) == 0:
                st.error("è®­ç»ƒæ•°æ®ä¸ºç©º")
                return None, None
            
            if algorithm == "Prophet":
                return self._prophet_forecast(train, metric, periods, freq)
            elif algorithm == "ARIMA":
                return self._arima_forecast(train, metric, periods)
            elif algorithm == "ExponentialSmoothing":
                return self._exp_smooth_forecast(train, metric, periods)
            elif algorithm == "RandomForest_TS":
                return self._ml_forecast(train, metric, periods, model_type='rf')
            elif algorithm == "XGBoost_TS":
                return self._ml_forecast(train, metric, periods, model_type='xgb')
            elif algorithm == "LSTM":
                return self._lstm_forecast(train, metric, periods)
                
        except Exception as e:
            st.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
            return None, None
    
    def _prophet_forecast(self, train, metric, periods, freq):
        try:
            from prophet import Prophet
        except ImportError:
            st.error("è¯·å…ˆå®‰è£… Prophet: pip install prophet")
            return None, None
        
        try:
            df_prophet = train.reset_index()
            df_prophet.columns = ['ds', 'y']
            
            # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            if len(df_prophet) < 2:
                st.error("Prophetéœ€è¦è‡³å°‘2ä¸ªæ•°æ®ç‚¹")
                return None, None
            
            model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)
            model.fit(df_prophet)
            
            future = model.make_future_dataframe(periods=periods, freq=freq)
            forecast = model.predict(future)
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df_prophet['ds'], y=df_prophet['y'], mode='lines+markers', 
                                   name='å†å²æ•°æ®', line=dict(color='#0369a1')))
            fig.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat'], mode='lines', 
                                   name='é¢„æµ‹å€¼', line=dict(color='#db2777')))
            fig.add_trace(go.Scatter(x=forecast['ds'].tail(periods), y=forecast['yhat'].tail(periods), 
                                   mode='lines', name='é¢„æµ‹åŒºé—´', fill=None, 
                                   line=dict(color='#f472b6', width=0)))
            fig.add_trace(go.Scatter(x=forecast['ds'].tail(periods), 
                                   y=forecast['yhat_upper'].tail(periods), 
                                   mode='lines', fill='tonexty', fillcolor='rgba(244, 114, 182, 0.2)',
                                   line=dict(width=0), showlegend=False))
            fig.add_trace(go.Scatter(x=forecast['ds'].tail(periods), 
                                   y=forecast['yhat_lower'].tail(periods), 
                                   mode='lines', fill='tonexty', fillcolor='rgba(244, 114, 182, 0.2)',
                                   line=dict(width=0), showlegend=False))
            
            fig.update_layout(title=f"{metric} - Propheté¢„æµ‹", height=500, plot_bgcolor='white')
            
            # å®‰å…¨è®¡ç®—MAPE
            actual = df_prophet['y'].values
            predicted = forecast['yhat'].iloc[:len(df_prophet)].values
            mask = actual != 0
            if mask.sum() > 0:
                mape = np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100
            else:
                mape = np.nan
            
            return fig, {
                'MAPE': mape,
                'è¶‹åŠ¿': 'ä¸Šå‡' if forecast['trend'].iloc[-1] > forecast['trend'].iloc[-30] else 'ä¸‹é™',
                'é¢„æµ‹å‡å€¼': forecast['yhat'].tail(periods).mean(),
                'æœ€åæ—¥æœŸ': forecast['ds'].max()
            }
        except Exception as e:
            st.error(f"Propheté¢„æµ‹å¤±è´¥: {str(e)}")
            return None, None
    
    def _arima_forecast(self, train, metric, periods):
        try:
            from statsmodels.tsa.arima.model import ARIMA
        except ImportError:
            st.error("è¯·å…ˆå®‰è£… statsmodels")
            return None, None
        
        try:
            # ç¡®ä¿æ•°æ®è¶³å¤Ÿ
            if len(train) < 10:
                st.error("ARIMAéœ€è¦è‡³å°‘10ä¸ªæ•°æ®ç‚¹")
                return None, None
            
            # ç®€åŒ–æ¨¡å‹é˜¶æ•°ä»¥é¿å…æ”¶æ•›é—®é¢˜
            model = ARIMA(train, order=(2, 1, 1))
            fitted = model.fit()
            
            forecast_result = fitted.get_forecast(steps=periods)
            forecast_mean = forecast_result.predicted_mean
            conf_int = forecast_result.conf_int()
            
            future_dates = pd.date_range(start=train.index[-1] + timedelta(days=1), periods=periods, freq=train.index.freq or 'D')
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=train.index, y=train[metric], mode='lines+markers', 
                                   name='å†å²æ•°æ®', line=dict(color='#0369a1')))
            fig.add_trace(go.Scatter(x=future_dates, y=forecast_mean, mode='lines', 
                                   name='é¢„æµ‹å€¼', line=dict(color='#dc2626')))
            fig.add_trace(go.Scatter(x=future_dates, y=conf_int.iloc[:, 1], mode='lines', 
                                   line=dict(width=0), showlegend=False))
            fig.add_trace(go.Scatter(x=future_dates, y=conf_int.iloc[:, 0], mode='lines', 
                                   fill='tonexty', fillcolor='rgba(220, 38, 38, 0.2)',
                                   line=dict(width=0), showlegend=False))
            
            fig.update_layout(title=f"{metric} - ARIMAé¢„æµ‹", height=500)
            
            return fig, {
                'AIC': fitted.aic if hasattr(fitted, 'aic') else None,
                'BIC': fitted.bic if hasattr(fitted, 'bic') else None,
                'é¢„æµ‹å‡å€¼': forecast_mean.mean()
            }
        except Exception as e:
            st.error(f"ARIMAé¢„æµ‹å¤±è´¥: {str(e)}")
            return None, None
    
    def _exp_smooth_forecast(self, train, metric, periods):
        try:
            from statsmodels.tsa.holtwinters import ExponentialSmoothing
        except ImportError:
            st.error("è¯·å…ˆå®‰è£… statsmodels")
            return None, None
        
        try:
            if len(train) < 10:
                st.error("æŒ‡æ•°å¹³æ»‘éœ€è¦è‡³å°‘10ä¸ªæ•°æ®ç‚¹")
                return None, None
            
            model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=7)
            fitted = model.fit()
            
            forecast = fitted.forecast(steps=periods)
            future_dates = pd.date_range(start=train.index[-1] + timedelta(days=1), periods=periods, freq=train.index.freq or 'D')
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=train.index, y=train[metric], mode='lines+markers', 
                                   name='å†å²æ•°æ®', line=dict(color='#0369a1')))
            fig.add_trace(go.Scatter(x=future_dates, y=forecast, mode='lines+markers', 
                                   name='é¢„æµ‹å€¼', line=dict(color='#059669')))
            
            fig.update_layout(title=f"{metric} - Holt-Wintersé¢„æµ‹", height=500)
            
            return fig, {
                'å¹³æ»‘æ°´å¹³': fitted.params.get('smoothing_level', None),
                'å¹³æ»‘è¶‹åŠ¿': fitted.params.get('smoothing_trend', None),
                'å¹³æ»‘å­£èŠ‚': fitted.params.get('smoothing_seasonal', None)
            }
        except Exception as e:
            st.error(f"æŒ‡æ•°å¹³æ»‘é¢„æµ‹å¤±è´¥: {str(e)}")
            return None, None
    
    def _ml_forecast(self, train, metric, periods, model_type='rf'):
        """æœºå™¨å­¦ä¹ é¢„æµ‹ï¼Œä¿®å¤ç´¢å¼•è¶Šç•Œé—®é¢˜"""
        try:
            # ç¡®ä¿è®­ç»ƒæ•°æ®è¶³å¤Ÿ
            if len(train) < 14:
                st.error(f"æœºå™¨å­¦ä¹ é¢„æµ‹éœ€è¦è‡³å°‘14ä¸ªæ•°æ®ç‚¹ï¼Œå½“å‰åªæœ‰{len(train)}ä¸ª")
                return None, None
            
            df_features = self.prepare_features(train[metric])
            
            if len(df_features) == 0:
                st.error("ç‰¹å¾å·¥ç¨‹åæ•°æ®ä¸ºç©º")
                return None, None
            
            X = df_features.drop('y', axis=1)
            y = df_features['y']
            
            if len(X) < 10:
                st.error("æœ‰æ•ˆè®­ç»ƒæ ·æœ¬ä¸è¶³")
                return None, None
            
            if model_type == 'rf':
                model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
            else:
                try:
                    import xgboost as xgb
                    model = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)
                except ImportError:
                    st.info("XGBoostæœªå®‰è£…ï¼Œä½¿ç”¨RandomForestæ›¿ä»£")
                    model = RandomForestRegressor(n_estimators=100, random_state=42)
            
            model.fit(X, y)
            
            # å®‰å…¨åœ°è·å–æœ€å30ä¸ªå€¼
            last_values_list = train[metric].values
            if len(last_values_list) >= 30:
                last_values = last_values_list[-30:]
            else:
                last_values = last_values_list
            
            if len(last_values) == 0:
                st.error("æ— æ³•è·å–å†å²å€¼è¿›è¡Œé¢„æµ‹")
                return None, None
            
            predictions = []
            current_values = list(last_values)  # è½¬ä¸ºåˆ—è¡¨æ–¹ä¾¿æ“ä½œ
            
            for i in range(periods):
                # æ„å»ºç‰¹å¾
                feat = {
                    'dayofweek': (train.index[-1] + timedelta(days=i+1)).weekday(),
                    'month': (train.index[-1] + timedelta(days=i+1)).month,
                    'day': (train.index[-1] + timedelta(days=i+1)).day,
                    'year': (train.index[-1] + timedelta(days=i+1)).year,
                }
                
                # å®‰å…¨åœ°è·å–æ»åç‰¹å¾
                for lag in range(1, 8):
                    if len(current_values) >= lag:
                        feat[f'lag_{lag}'] = current_values[-lag]
                    else:
                        feat[f'lag_{lag}'] = current_values[0] if current_values else 0
                
                # å®‰å…¨åœ°è®¡ç®—æ»šåŠ¨ç»Ÿè®¡
                if len(current_values) >= 7:
                    feat['rolling_mean_7'] = np.mean(current_values[-7:])
                    feat['rolling_std_7'] = np.std(current_values[-7:])
                else:
                    feat['rolling_mean_7'] = np.mean(current_values) if current_values else 0
                    feat['rolling_std_7'] = np.std(current_values) if len(current_values) > 1 else 0
                
                feat['expanding_mean'] = np.mean(current_values) if current_values else 0
                
                # å®‰å…¨åœ°è®¡ç®—å·®åˆ†
                if len(current_values) >= 2:
                    feat['diff_1'] = current_values[-1] - current_values[-2]
                else:
                    feat['diff_1'] = 0
                
                if len(current_values) >= 7:
                    feat['diff_7'] = current_values[-1] - current_values[-7]
                else:
                    feat['diff_7'] = 0
                
                X_pred = pd.DataFrame([feat])
                pred = model.predict(X_pred)[0]
                predictions.append(pred)
                current_values.append(pred)  # æ·»åŠ åˆ°å†å²å€¼ä¸­ç”¨äºä¸‹ä¸€ä¸ªé¢„æµ‹
            
            future_dates = pd.date_range(start=train.index[-1] + timedelta(days=1), periods=periods, freq='D')
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=train.index, y=train[metric], mode='lines', name='å†å²æ•°æ®', line=dict(color='#0369a1')))
            fig.add_trace(go.Scatter(x=future_dates, y=predictions, mode='lines+markers', 
                                   name='é¢„æµ‹å€¼', line=dict(color='#7c3aed')))
            
            fig.update_layout(title=f"{metric} - {model_type.upper()}æ—¶åºé¢„æµ‹", height=500)
            
            importance = pd.DataFrame({
                'ç‰¹å¾': X.columns,
                'é‡è¦æ€§': model.feature_importances_
            }).sort_values('é‡è¦æ€§', ascending=False)
            
            return fig, {
                'æ¨¡å‹': model_type,
                'è®­ç»ƒé›†RÂ²': model.score(X, y),
                'Top3ç‰¹å¾': importance.head(3)['ç‰¹å¾'].tolist(),
                'é¢„æµ‹è¶‹åŠ¿': 'ä¸Šå‡' if predictions[-1] > predictions[0] else 'ä¸‹é™'
            }
        except Exception as e:
            st.error(f"æœºå™¨å­¦ä¹ é¢„æµ‹å¤±è´¥: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
            return None, None
    
    def _lstm_forecast(self, train, metric, periods):
        """LSTMé¢„æµ‹ï¼Œç®€åŒ–ç‰ˆæœ¬é¿å…ç´¢å¼•é—®é¢˜"""
        st.warning("LSTMé¢„æµ‹æš‚ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–ç®—æ³•")
        return None, None

class StatsModule:
    def __init__(self, df):
        self.df = df
    
    def descriptive_stats(self, columns):
        stats_list = []
        for col in columns:
            if col in self.df.columns:
                data = self.df[col].dropna()
                stats_list.append({
                    'å­—æ®µ': col, 'æ ·æœ¬æ•°': len(data), 'å‡å€¼': data.mean(),
                    'ä¸­ä½æ•°': data.median(), 'æ ‡å‡†å·®': data.std(),
                    'æœ€å°å€¼': data.min(), 'æœ€å¤§å€¼': data.max(),
                    '25%åˆ†ä½æ•°': data.quantile(0.25), '75%åˆ†ä½æ•°': data.quantile(0.75),
                    'ååº¦': data.skew(), 'å³°åº¦': data.kurtosis(),
                    'å˜å¼‚ç³»æ•°': data.std()/data.mean() if data.mean() != 0 else np.nan
                })
        return pd.DataFrame(stats_list)
    
    def correlation(self, columns):
        corr = self.df[columns].corr()
        fig = go.Figure(data=go.Heatmap(
            z=corr.values, x=corr.columns, y=corr.columns,
            text=np.round(corr.values, 2), texttemplate='%{text}',
            colorscale=[[0, '#16a34a'], [0.5, '#ffffff'], [1, '#dc2626']],
            zmid=0, zmin=-1, zmax=1
        ))
        fig.update_layout(title="ç›¸å…³æ€§çƒ­åŠ›å›¾", height=500)
        return corr, fig
    
    def normality_test(self, column):
        data = self.df[column].dropna()
        if len(data) < 3:
            return None, None
        stat, p = stats.shapiro(data)
        return stat, p

def create_treemap_figure(df, dims, metric, title):
    plot_df = df[df[dims[0]] != 'ã€æ€»è®¡ã€‘'].copy() if 'ã€æ€»è®¡ã€‘' in df[dims[0]].values else df.copy()
    
    if len(dims) == 2:
        path = dims
        values = metric
    else:
        path = dims
        values = metric
    
    try:
        fig = px.treemap(plot_df, path=path, values=values, 
                        title=title, color=metric, color_continuous_scale='RdBu')
        fig.update_layout(height=600)
        return fig
    except:
        return None

def create_sunburst_figure(df, dims, metric):
    plot_df = df[df[dims[0]] != 'ã€æ€»è®¡ã€‘'].copy() if 'ã€æ€»è®¡ã€‘' in df[dims[0]].values else df.copy()
    
    try:
        fig = px.sunburst(plot_df, path=dims, values=metric, color=metric,
                         color_continuous_scale='RdBu')
        fig.update_layout(height=600)
        return fig
    except:
        return None

def render_welcome():
    st.markdown("### æ™ºèƒ½æ•°æ®åˆ†æå¹³å°")
    st.caption("Advanced Analytics Platform | ä¸Šä¼ æ•°æ®å¼€å§‹æ™ºèƒ½åˆ†æä¹‹æ—…")

def render_upload():
    st.markdown('<div class="section-title">æ•°æ®ä¸Šä¼ </div>', unsafe_allow_html=True)
    uploaded_file = st.file_uploader("é€‰æ‹©CSVæˆ–Excelæ–‡ä»¶", type=['csv', 'xlsx', 'xls'])
    
    if uploaded_file and not st.session_state.data_loaded:
        with st.spinner("æ­£åœ¨æ™ºèƒ½è§£ææ•°æ®..."):
            file_bytes = uploaded_file.getvalue()
            df = load_data(file_bytes, uploaded_file.name)
            if df is not None:
                df, date_cols, num_cols, cat_cols = detect_column_types(df)
                st.session_state.df = df
                st.session_state.df_original = df.copy()
                st.session_state.file_name = uploaded_file.name
                st.session_state.date_columns = date_cols
                st.session_state.numeric_columns = num_cols
                st.session_state.categorical_columns = cat_cols
                st.session_state.data_loaded = True
                st.rerun()
            else:
                st.error("æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ ¼å¼")

def render_data_summary():
    """åœ¨åŠŸèƒ½é€‰æ‹©ä¸Šæ–¹å±•ç¤ºæ•°æ®æ¦‚å†µï¼ˆå­—ä½“å‡å°ç‰ˆï¼‰"""
    if not st.session_state.data_loaded:
        return
    
    df = st.session_state.df
    dates = st.session_state.date_columns
    
    n_days = 0
    if dates and dates[0] in df.columns:
        n_days = df[dates[0]].nunique()
    
    n_cols = len(df.columns)
    
    st.markdown('<div class="section-title">æ•°æ®æ¦‚å†µ</div>', unsafe_allow_html=True)
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"<div class='data-summary'>æ•°æ®å¤©æ•°</div><div class='data-summary-value'>{n_days} å¤©</div>" if n_days > 0 else "<div class='data-summary'>-</div>", unsafe_allow_html=True)
    with col2:
        st.markdown(f"<div class='data-summary'>å­—æ®µåˆ—æ•°</div><div class='data-summary-value'>{n_cols} åˆ—</div>", unsafe_allow_html=True)
    st.markdown("<div style='margin-bottom: 1rem;'></div>", unsafe_allow_html=True)

def render_module_buttons():
    if not st.session_state.data_loaded:
        return None
    
    st.markdown('<div class="section-title">åŠŸèƒ½é€‰æ‹©</div>', unsafe_allow_html=True)
    modules = ["æ•°æ®æ¦‚è§ˆ", "å¼‚åŠ¨å½’å› ", "äº¤å‰åˆ†æ", "è¶‹åŠ¿åˆ†æ", "å¯è§†åŒ–", "ç»Ÿè®¡åˆ†æ", "æœºå™¨å­¦ä¹ ", "é¢„æµ‹åˆ†æ", "æ•°æ®æ¸…æ´—"]
    
    cols = st.columns(3)
    for idx, module in enumerate(modules):
        with cols[idx % 3]:
            btn_type = "primary" if st.session_state.current_module == module else "secondary"
            if st.button(module, key=f"mod_{module}", use_container_width=True, type=btn_type):
                st.session_state.current_module = module
                st.rerun()
    
    return st.session_state.current_module

def render_config(module):
    if not module:
        return None
    st.markdown('<div class="section-title">åˆ†æé…ç½®</div>', unsafe_allow_html=True)
    df = st.session_state.df
    dims = st.session_state.categorical_columns
    metrics = st.session_state.numeric_columns
    dates = st.session_state.date_columns
    
    selected_dims = []
    selected_metrics = []
    date_col = None
    time_range = None
    extra = None
    
    col_a, col_b = st.columns(2)
    with col_a:
        dim_html = " ".join([f"<span class='dim-tag'>{d}</span>" for d in dims])
        if len(dims) > 15:
            dim_html = " ".join([f"<span class='dim-tag'>{d}</span>" for d in dims[:15]]) + " <span class='dim-tag'>...</span>"
        st.markdown(f"**å¯ç”¨ç»´åº¦:** {dim_html}", unsafe_allow_html=True)
    with col_b:
        metric_html = " ".join([f"<span class='metric-tag'>{m}</span>" for m in metrics])
        if len(metrics) > 15:
            metric_html = " ".join([f"<span class='metric-tag'>{m}</span>" for m in metrics[:15]]) + " <span class='metric-tag'>...</span>"
        st.markdown(f"**å¯ç”¨æŒ‡æ ‡:** {metric_html}", unsafe_allow_html=True)
    
    if dates:
        default_date_idx = 0
    else:
        default_date_idx = None
    
    if module in ["å¼‚åŠ¨å½’å› "]:
        col1, col2 = st.columns(2)
        with col1:
            selected_dims = st.multiselect("åˆ†æç»´åº¦", dims, default=dims[:1] if dims else [])
        with col2:
            selected_metrics = st.multiselect("åˆ†ææŒ‡æ ‡", metrics, default=metrics[:1] if metrics else [])
        if dates:
            st.markdown("**æ—¶é—´èŒƒå›´è®¾å®š**")
            date_col = st.selectbox("æ—¥æœŸå­—æ®µ", dates, index=default_date_idx, key="attr_date")
            if date_col:
                time_range = render_time_range_selector(df, date_col)
    
    elif module == "äº¤å‰åˆ†æ":
        col1, col2 = st.columns(2)
        with col1:
            default_dims = dims[:2] if len(dims) >= 2 else dims[:1] if dims else []
            selected_dims = st.multiselect("äº¤å‰ç»´åº¦ï¼ˆæ”¯æŒ2+ç»´åº¦ï¼‰", dims, default=default_dims)
            if len(selected_dims) < 2:
                st.warning("è¯·è‡³å°‘é€‰æ‹©2ä¸ªç»´åº¦è¿›è¡Œäº¤å‰åˆ†æ")
        with col2:
            selected_metrics = st.multiselect("åˆ†ææŒ‡æ ‡", metrics, default=metrics[:1] if metrics else [])
        if dates:
            date_col = st.selectbox("æ—¥æœŸå­—æ®µ", dates, index=default_date_idx, key="cross_date")
            if date_col:
                time_range = render_time_range_selector(df, date_col)
    
    elif module == "è¶‹åŠ¿åˆ†æ":
        col1, col2 = st.columns(2)
        with col1:
            selected_dims = st.multiselect("ç»´åº¦ï¼ˆå¯é€‰ï¼Œä¸é€‰çœ‹æ€»ä½“ï¼‰", dims, default=dims[:1] if dims else [])
        with col2:
            selected_metrics = st.multiselect("æŒ‡æ ‡", metrics, default=metrics[:1] if metrics else [])
        if dates:
            date_col = st.selectbox("æ—¥æœŸå­—æ®µ", dates, index=default_date_idx, key="trend_date")
    
    elif module == "æ•°æ®æ¦‚è§ˆ":
        if metrics:
            default_metrics = metrics[:min(5, len(metrics))]
            selected_metrics = st.multiselect("å±•ç¤ºæŒ‡æ ‡ï¼ˆæœ€å¤šé€‰5ä¸ªï¼‰", metrics, default=default_metrics, max_selections=5)
        if dates:
            date_col = st.selectbox("æ—¥æœŸå­—æ®µï¼ˆå¯é€‰ï¼‰", ['æ— '] + dates, index=default_date_idx+1 if default_date_idx is not None else 0, key="overview_date")
            if date_col == 'æ— ':
                date_col = None
    
    elif module == "å¯è§†åŒ–":
        viz_type = st.selectbox("å›¾è¡¨ç±»å‹", ["æ•£ç‚¹å›¾", "æŠ˜çº¿å›¾", "æŸ±çŠ¶å›¾", "ç®±çº¿å›¾", "çƒ­åŠ›å›¾", "é¥¼å›¾"])
        if viz_type == "çƒ­åŠ›å›¾":
            selected_metrics = st.multiselect("æŒ‡æ ‡", metrics, default=metrics[:4] if metrics else [])
        elif viz_type == "é¥¼å›¾":
            col1, col2 = st.columns(2)
            with col1:
                selected_dims = st.selectbox("ç»´åº¦", dims)
            with col2:
                selected_metrics = st.selectbox("æŒ‡æ ‡", metrics)
        else:
            col1, col2 = st.columns(2)
            with col1:
                selected_dims = st.multiselect("ç»´åº¦", dims)
            with col2:
                selected_metrics = st.multiselect("æŒ‡æ ‡", metrics, default=metrics[:1] if metrics else [])
        extra = viz_type
    
    elif module == "ç»Ÿè®¡åˆ†æ":
        selected_metrics = st.multiselect("åˆ†ææŒ‡æ ‡", metrics, default=metrics[:4] if metrics else [])
    
    elif module == "æœºå™¨å­¦ä¹ ":
        task_type = st.selectbox("ä»»åŠ¡ç±»å‹", list(ML_ALGORITHMS.keys()))
        algorithm = st.selectbox("ç®—æ³•é€‰æ‹©", list(ML_ALGORITHMS[task_type].keys()))
        
        algo_info = ML_ALGORITHMS[task_type][algorithm]
        st.markdown(f"""
        <div class='algorithm-card'>
            <div class='algorithm-title'>{algo_info['name']}</div>
            <div><b>ä»‹ç»ï¼š</b>{algo_info['desc']}</div>
        </div>
        """, unsafe_allow_html=True)
        
        params = {}
        for param_name, param_config in algo_info['params'].items():
            if isinstance(param_config, tuple):
                params[param_name] = st.slider(param_name, param_config[0], param_config[1], param_config[2])
            elif isinstance(param_config, list):
                params[param_name] = st.selectbox(param_name, param_config)
        
        if task_type == "é™ç»´åˆ†æ":
            selected_metrics = st.multiselect("ç‰¹å¾å˜é‡", metrics, default=metrics[:4] if metrics else [])
            if algorithm == "FeatureImportance":
                target = st.selectbox("ç›®æ ‡å˜é‡", metrics)
                selected_metrics = {"features": selected_metrics, "target": target}
        else:
            col1, col2 = st.columns(2)
            with col1:
                if task_type in ["å›å½’åˆ†æ", "åˆ†ç±»åˆ†æ", "ç‰¹å¾é‡è¦æ€§"]:
                    target = st.selectbox("ç›®æ ‡å˜é‡", metrics)
                    features = st.multiselect("ç‰¹å¾å˜é‡", [m for m in metrics if m != target], default=[m for m in metrics if m != target][:3])
                    selected_metrics = {"target": target, "features": features}
                else:
                    selected_metrics = st.multiselect("ç‰¹å¾å˜é‡", metrics, default=metrics[:2] if len(metrics) >= 2 else metrics)
            with col2:
                if task_type in ["èšç±»åˆ†æ", "å¼‚å¸¸æ£€æµ‹"]:
                    st.info(f"{algo_info['name']}æ— éœ€ç›®æ ‡å˜é‡ï¼Œå°†åŸºäºç‰¹å¾åˆ†å¸ƒè¿›è¡Œåˆ†æ")
        
        extra = {"task": task_type, "algorithm": algorithm, "params": params}
    
    elif module == "é¢„æµ‹åˆ†æ":
        if dates:
            date_col = st.selectbox("æ—¥æœŸå­—æ®µ", dates, index=default_date_idx, key="forecast_date")
            selected_metric = st.selectbox("é¢„æµ‹æŒ‡æ ‡", metrics)
            periods = st.slider("é¢„æµ‹å‘¨æœŸæ•°", 7, 90, 30)
            
            algorithm = st.selectbox("é¢„æµ‹ç®—æ³•", list(FORECAST_ALGORITHMS.keys()), 
                                   format_func=lambda x: FORECAST_ALGORITHMS[x]['name'])
            
            algo_info = FORECAST_ALGORITHMS[algorithm]
            st.markdown(f"""
            <div class='info-box'>
                <b>ç®—æ³•ç‰¹ç‚¹ï¼š</b>{algo_info['desc']}<br>
                <b>é€‚ç”¨åœºæ™¯ï¼š</b>{algo_info['best_for']}<br>
                <b>å¤æ‚åº¦ï¼š</b>{algo_info['complexity']}
            </div>
            """, unsafe_allow_html=True)
            
            selected_metrics = {'metric': selected_metric, 'periods': periods, 'algorithm': algorithm}
        else:
            st.warning("éœ€è¦æ—¶é—´å­—æ®µè¿›è¡Œé¢„æµ‹åˆ†æ")
    
    return selected_dims, selected_metrics, date_col, time_range, extra

def style_contribution_df(df, is_cross=False, dims=None):
    """é€šç”¨æ ·å¼å‡½æ•°ï¼Œä»…å¯¹è´¡çŒ®ppåˆ—è¿›è¡Œçº¢ç»¿é¢œè‰²æ ‡æ³¨"""
    format_dict = {
        'åŸºæœŸå€¼': smart_format,
        'ç›®æ ‡æœŸå€¼': smart_format,
        'å˜åŠ¨': smart_format,
        'å˜åŠ¨ç‡': '{:.2f}%',
        'è´¡çŒ®ç™¾åˆ†æ¯”': '{:.2f}%'
    }
    
    if 'è´¡çŒ®pp' in df.columns:
        format_dict['è´¡çŒ®pp'] = '{:.2f}pp'
    
    # åŸºç¡€æ ·å¼ï¼ˆä»…æ ¼å¼åŒ–ï¼Œä¸è®¾ç½®é¢œè‰²ï¼‰
    styled = df.style.format(format_dict)
    
    # åªæœ‰è´¡çŒ®ppåˆ—è®¾ç½®é¢œè‰²
    if 'è´¡çŒ®pp' in df.columns:
        def color_pp_column(col):
            colors = []
            for idx, val in enumerate(col):
                # åˆ¤æ–­æ˜¯å¦æ˜¯æ€»è®¡è¡Œ
                is_total = False
                if is_cross:
                    if 'ç»´åº¦å€¼' in df.columns:
                        is_total = df.iloc[idx]['ç»´åº¦å€¼'] == 'ã€æ€»è®¡ã€‘'
                    elif 'ç»„åˆç»´åº¦' in df.columns:
                        is_total = df.iloc[idx]['ç»„åˆç»´åº¦'] == 'ã€æ€»è®¡ã€‘'
                    elif dims and len(dims) > 0:
                        is_total = str(df.iloc[idx][dims[0]]) == 'ã€æ€»è®¡ã€‘'
                    else:
                        is_total = str(df.iloc[idx, 0]) == 'ã€æ€»è®¡ã€‘'
                
                # æ€»è®¡è¡Œæˆ–éæ ‡é‡å€¼ä¸ç€è‰²
                if is_total or not isinstance(val, (int, float)):
                    colors.append('')
                else:
                    # ä¸Šæ¶¨çº¢è‰²ï¼Œä¸‹è·Œç»¿è‰²
                    if val > 0:
                        colors.append('color: #dc2626')
                    elif val < 0:
                        colors.append('color: #16a34a')
                    else:
                        colors.append('')
            return colors
        
        styled = styled.apply(color_pp_column, subset=['è´¡çŒ®pp'])
    
    return styled

def render_results(module, dims, metrics, date_col, time_range, extra):
    df = st.session_state.df
    if module == "æ•°æ®æ¦‚è§ˆ":
        render_overview(df, metrics, date_col)
    elif module == "å¼‚åŠ¨å½’å› ":
        render_attribution(df, dims, metrics, date_col, time_range)
    elif module == "äº¤å‰åˆ†æ":
        render_cross(df, dims, metrics, date_col, time_range)
    elif module == "è¶‹åŠ¿åˆ†æ":
        render_trend(df, dims, metrics, date_col)
    elif module == "å¯è§†åŒ–":
        render_visualization(df, dims, metrics, extra)
    elif module == "ç»Ÿè®¡åˆ†æ":
        render_statistics(df, metrics)
    elif module == "æœºå™¨å­¦ä¹ ":
        render_ml(df, metrics, extra)
    elif module == "é¢„æµ‹åˆ†æ":
        render_forecast(df, date_col, metrics)
    elif module == "æ•°æ®æ¸…æ´—":
        render_cleaning(df)

def render_overview(df, metrics, date_col):
    st.markdown('<div class="section-title">æ•°æ®æ¦‚è§ˆ</div>', unsafe_allow_html=True)
    
    if date_col and date_col in df.columns and metrics:
        col1, col2 = st.columns([3, 1])
        with col2:
            period = st.selectbox("æ—¶é—´å£å¾„", ["å¤©", "å‘¨", "æœˆ", "å¹´"], key="overview_period")
        
        df[date_col] = pd.to_datetime(df[date_col])
        
        if period == "å¤©":
            ts_df = df.groupby(date_col)[metrics].sum().reset_index()
            ts_df = ts_df.sort_values(date_col)
            x_col = date_col
        elif period == "å‘¨":
            df['period'] = df[date_col].dt.to_period('W').astype(str)
            ts_df = df.groupby('period')[metrics].sum().reset_index()
            x_col = 'period'
        elif period == "æœˆ":
            df['period'] = df[date_col].dt.to_period('M').astype(str)
            ts_df = df.groupby('period')[metrics].sum().reset_index()
            x_col = 'period'
        elif period == "å¹´":
            df['period'] = df[date_col].dt.to_period('Y').astype(str)
            ts_df = df.groupby('period')[metrics].sum().reset_index()
            x_col = 'period'
        
        st.markdown("**æ—¶é—´çº¿è¶‹åŠ¿**")
        
        fig = go.Figure()
        colors = px.colors.qualitative.Bold
        for idx, metric in enumerate(metrics):
            fig.add_trace(go.Scatter(
                x=ts_df[x_col], y=ts_df[metric],
                mode='lines+markers', name=metric,
                line=dict(color=colors[idx % len(colors)], width=2.5),
                marker=dict(size=6)
            ))
        fig.update_layout(
            height=450, plot_bgcolor='white', paper_bgcolor='white',
            yaxis=dict(gridcolor='#e2e8f0', tickformat=','),
            xaxis=dict(gridcolor='#e2e8f0'),
            legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),
            hovermode='x unified'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("**ç»´åº¦åˆ†å¸ƒåˆ†æï¼ˆæœ€æ–°ä¸€å¤©ï¼‰**")
        st.markdown('<p class="small-note">ä»¥ä¸‹é¥¼å›¾ä»…åŸºäºæœ€æ–°ä¸€å¤©çš„æ•°æ®åˆ†å¸ƒ</p>', unsafe_allow_html=True)
        
        all_dims = st.session_state.categorical_columns
        
        if all_dims and date_col:
            latest_date = df[date_col].max()
            latest_df = df[df[date_col] == latest_date]
            
            st.markdown(f"<p class='small-note'>æ•°æ®æ—¥æœŸï¼š{latest_date.strftime('%Y-%m-%d')} | è¯¥æ—¥æ€»è®°å½•æ•°ï¼š{len(latest_df)}</p>", unsafe_allow_html=True)
            
            display_dims = all_dims[:6]
            dim_cols = st.columns(3)
            
            for idx, dim in enumerate(display_dims):
                with dim_cols[idx % 3]:
                    dim_counts = latest_df[dim].value_counts().head(8)
                    if len(dim_counts) > 0:
                        fig_pie = px.pie(values=dim_counts.values, names=dim_counts.index, 
                                       title=f"{dim} åˆ†å¸ƒ", hole=0.4)
                        fig_pie.update_layout(height=280, showlegend=False, 
                                            margin=dict(l=20, r=20, t=40, b=20),
                                            title_font_size=14)
                        fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                        st.plotly_chart(fig_pie, use_container_width=True)
            
            st.markdown("**ç»´åº¦è¯¦ç»†æ±‡æ€»ï¼ˆæœ€æ–°ä¸€å¤©ï¼‰**")
            selected_dim = st.selectbox("é€‰æ‹©ç»´åº¦æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡", all_dims, key="overview_dim_select")
            if metrics:
                selected_metric = st.selectbox("é€‰æ‹©æ±‡æ€»æŒ‡æ ‡", metrics, key="overview_metric_select")
                
                dim_summary = latest_df.groupby(selected_dim)[selected_metric].agg(['sum', 'mean', 'count']).reset_index()
                dim_summary.columns = [selected_dim, 'æ€»è®¡', 'å¹³å‡', 'è®°å½•æ•°']
                dim_summary = dim_summary.sort_values('æ€»è®¡', ascending=False)
                
                total_row = pd.DataFrame([{
                    selected_dim: 'ã€æ€»è®¡ã€‘',
                    'æ€»è®¡': dim_summary['æ€»è®¡'].sum(),
                    'å¹³å‡': latest_df[selected_metric].mean(),
                    'è®°å½•æ•°': dim_summary['è®°å½•æ•°'].sum()
                }])
                dim_summary = pd.concat([total_row, dim_summary], ignore_index=True)
                
                st.dataframe(dim_summary.style.format({'æ€»è®¡': smart_format, 'å¹³å‡': smart_format, 'è®°å½•æ•°': '{:,}'}), 
                           use_container_width=True)
    
    st.markdown("**æ•°æ®é¢„è§ˆï¼ˆå‰50è¡Œï¼‰**")
    st.dataframe(df.head(50).style.format(smart_format), use_container_width=True)

def render_attribution(df, dims, metrics, date_col, time_range):
    st.markdown('<div class="section-title">å¼‚åŠ¨å½’å› åˆ†æ</div>', unsafe_allow_html=True)
    
    if not dims or not metrics or not date_col or not time_range or None in time_range:
        st.info("è¯·å®Œæˆé…ç½®å¹¶é€‰æ‹©æ—¶é—´èŒƒå›´")
        return
    
    base_start, base_end, target_start, target_end = time_range
    st.markdown(f"<div class='info-box'>åˆ†ææ—¶æ®µ | åŸºæœŸ: {base_start} ~ {base_end} | ç›®æ ‡æœŸ: {target_start} ~ {target_end}`</div>", unsafe_allow_html=True)
    
    st.markdown("**å…¨ç»´åº¦è‡ªåŠ¨å½’å› **")
    
    all_dims = st.session_state.categorical_columns
    
    top_n = st.slider("æ¯ç»´åº¦å±•ç¤ºTop N", 5, 50, 10, key="auto_attr_top_n")
    
    if st.button("è¿è¡Œå…¨ç»´åº¦å½’å› ", type="primary", use_container_width=True):
        progress_bar = st.progress(0)
        engine = AttributionEngine()
        
        display_dims = all_dims[:6]
        results_tabs = st.tabs([f"{dim}" for dim in display_dims])
        
        for idx, dim in enumerate(display_dims):
            with results_tabs[idx]:
                with st.spinner(f"åˆ†æ {dim}..."):
                    result_df, total_change, total_base, total_target, total_rate = engine.calculate_contribution(
                        df, dim, metrics[0], date_col, base_start, base_end, target_start, target_end
                    )
                    if result_df is not None:
                        total_row = result_df[result_df['ç»´åº¦å€¼'] == 'ã€æ€»è®¡ã€‘']
                        detail_rows = result_df[result_df['ç»´åº¦å€¼'] != 'ã€æ€»è®¡ã€‘']
                        
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("åŸºæœŸ", smart_format(total_base))
                        with col2:
                            st.metric("ç›®æ ‡æœŸ", smart_format(total_target))
                        with col3:
                            st.metric("å˜åŠ¨", f"{total_change:+,.2f}", f"{total_rate:.2f}%")
                        with col4:
                            st.metric("ç»´åº¦å€¼æ•°", len(detail_rows))
                        
                        chart_data = detail_rows.head(15)
                        fig = go.Figure()
                        fig.add_trace(go.Bar(x=chart_data['ç»´åº¦å€¼'], y=chart_data['åŸºæœŸå€¼'], 
                                           name='åŸºæœŸ', marker_color='#94a3b8', opacity=0.7))
                        fig.add_trace(go.Bar(x=chart_data['ç»´åº¦å€¼'], y=chart_data['ç›®æ ‡æœŸå€¼'], 
                                           name='ç›®æ ‡æœŸ', marker_color='#0ea5e9'))
                        fig.update_layout(barmode='group', height=300, margin=dict(l=20, r=20, t=30, b=80),
                                        xaxis_tickangle=-45, showlegend=True, legend=dict(orientation='h', yanchor='bottom', y=1.02))
                        st.plotly_chart(fig, use_container_width=True)
                        
                        display_df = pd.concat([total_row, detail_rows.head(top_n)], ignore_index=True)
                        st.dataframe(style_contribution_df(display_df, is_cross=False), use_container_width=True, height=300)
            
            progress_bar.progress((idx + 1) / len(display_dims))

def render_cross(df, dims, metrics, date_col, time_range):
    st.markdown('<div class="section-title">äº¤å‰åˆ†æï¼ˆæ”¯æŒå¤šç»´åº¦ï¼‰</div>', unsafe_allow_html=True)
    
    if not dims or not metrics or not date_col or not time_range or None in time_range:
        st.info("è¯·å®Œæˆé…ç½®å¹¶é€‰æ‹©è‡³å°‘2ä¸ªç»´åº¦å’Œæ—¶é—´èŒƒå›´")
        return
    
    if len(dims) < 2:
        st.warning("è¯·è‡³å°‘é€‰æ‹©2ä¸ªç»´åº¦è¿›è¡Œäº¤å‰åˆ†æ")
        return
    
    base_start, base_end, target_start, target_end = time_range
    st.markdown(f"<div class='info-box'>åˆ†ææ—¶æ®µ | åŸºæœŸ: {base_start} ~ {base_end} | ç›®æ ‡æœŸ: {target_start} ~ {target_end}</div>", unsafe_allow_html=True)
    
    st.markdown(f"**å·²é€‰ç»´åº¦ ({len(dims)}ä¸ª):** " + " | ".join([f"**{d}**" for d in dims]))
    
    if st.button("å¼€å§‹äº¤å‰åˆ†æ", type="primary", use_container_width=True):
        with st.spinner("æ­£åœ¨è¿›è¡Œå¤šç»´åº¦äº¤å‰è®¡ç®—..."):
            engine = AttributionEngine()
            result_display, total_change, total_base, total_target = engine.multi_dim_analysis(
                df, dims, metrics[0], date_col, base_start, base_end, target_start, target_end
            )
            
            if result_display is not None:
                st.markdown(f"<div class='success-box'>æ€»è®¡: {smart_format(total_base)} â†’ {smart_format(total_target)} | å˜åŠ¨: {total_change:+,.2f} ({total_change/total_base*100:.2f}%)</div>", unsafe_allow_html=True)
                
                if len(dims) == 2:
                    tab1, tab2 = st.tabs(["çƒ­åŠ›å›¾", "æ˜ç»†è¡¨"])
                    with tab1:
                        pivot_data = result_display[result_display[dims[0]] != 'ã€æ€»è®¡ã€‘']
                        pivot_table = pivot_data.pivot_table(
                            index=dims[0], columns=dims[1], values='å˜åŠ¨', fill_value=0
                        )
                        # çº¢ç»¿é…è‰²ï¼šè´Ÿå€¼ç»¿è‰²ï¼Œæ­£å€¼çº¢è‰²ï¼Œ0ä¸ºç™½è‰²
                        fig = px.imshow(
                            pivot_table, 
                            text_auto=True, 
                            aspect="auto", 
                            color_continuous_scale=[(0, "#86efac"), (0.5, "#ffffff"), (1, "#fca5a5")],
                            color_continuous_midpoint=0
                        )
                        fig.update_layout(height=500, title="å˜åŠ¨å¹…åº¦çƒ­åŠ›å›¾")
                        st.plotly_chart(fig, use_container_width=True)
                    with tab2:
                        # ä½¿ç”¨äº¤å‰åˆ†æä¸“ç”¨æ ·å¼ï¼Œä¼ é€’dimså‚æ•°
                        st.dataframe(style_contribution_df(result_display, is_cross=True, dims=dims), use_container_width=True, height=500)
                else:
                    st.markdown("**å¤šç»´åº¦å¯è§†åŒ–å±•ç¤º**")
                    viz_col1, viz_col2 = st.columns(2)
                    
                    with viz_col1:
                        fig_tree = create_treemap_figure(result_display, dims, 'ç›®æ ‡æœŸå€¼', f"{' | '.join(dims)} å±‚çº§ç»“æ„")
                        if fig_tree:
                            st.plotly_chart(fig_tree, use_container_width=True)
                    
                    with viz_col2:
                        fig_sun = create_sunburst_figure(result_display, dims, 'ç›®æ ‡æœŸå€¼')
                        if fig_sun:
                            st.plotly_chart(fig_sun, use_container_width=True)
                    
                    st.markdown("**å±‚çº§æ˜ç»†æ•°æ®**")
                    st.dataframe(style_contribution_df(result_display, is_cross=True, dims=dims), use_container_width=True, height=500)

def render_trend(df, dims, metrics, date_col):
    st.markdown('<div class="section-title">è¶‹åŠ¿åˆ†æ</div>', unsafe_allow_html=True)
    
    if not metrics or not date_col:
        st.info("è¯·å®Œæˆé…ç½®")
        return
    
    metric = metrics[0]
    df[date_col] = pd.to_datetime(df[date_col])
    
    if st.button("å¼€å§‹è¶‹åŠ¿åˆ†æ", type="primary"):
        with st.spinner("è®¡ç®—è¶‹åŠ¿..."):
            if dims:
                trend_df = df.groupby([date_col, dims[0]])[metric].sum().reset_index()
                
                fig = px.line(trend_df, x=date_col, y=metric, color=dims[0], 
                            markers=True, title=f"{metric} åˆ†{dims[0]}è¶‹åŠ¿")
                fig.update_layout(height=500, hovermode='x unified')
                st.plotly_chart(fig, use_container_width=True)
                
                growth_data = []
                for dim_val in trend_df[dims[0]].unique():
                    subdf = trend_df[trend_df[dims[0]] == dim_val].sort_values(date_col)
                    if len(subdf) >= 2:
                        first, last = subdf[metric].iloc[0], subdf[metric].iloc[-1]
                        growth_data.append({
                            dims[0]: dim_val,
                            'é¦–å€¼': first, 'æœ«å€¼': last,
                            'å˜åŠ¨': last - first,
                            'å¢é•¿ç‡%': (last-first)/first*100 if first != 0 else 0,
                            'å‡å€¼': subdf[metric].mean(),
                            'è¶‹åŠ¿': 'ä¸Šå‡' if last > first else 'ä¸‹é™' if last < first else 'å¹³ç¨³'
                        })
                
                growth_df = pd.DataFrame(growth_data).sort_values('å˜åŠ¨', key=abs, ascending=False)
                
                styled_growth = growth_df.style.format({
                    'é¦–å€¼': smart_format, 
                    'æœ«å€¼': smart_format,
                    'å˜åŠ¨': lambda x: f"{x:+,.2f}",
                    'å¢é•¿ç‡%': '{:.2f}%', 
                    'å‡å€¼': smart_format
                }).map(lambda x: 'color: #dc2626' if x > 0 else 'color: #16a34a' if x < 0 else '', 
                       subset=['å˜åŠ¨', 'å¢é•¿ç‡%'])
                
                st.dataframe(styled_growth, use_container_width=True)
            else:
                total_trend = df.groupby(date_col)[metric].sum().reset_index()
                fig = px.line(total_trend, x=date_col, y=metric, markers=True, title=f"{metric} æ•´ä½“è¶‹åŠ¿")
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)

def render_visualization(df, dims, metrics, viz_type):
    st.markdown('<div class="section-title">å¯è§†åŒ–</div>', unsafe_allow_html=True)
    
    # ç§»é™¤æŠ½æ ·ï¼Œä½¿ç”¨å…¨é‡æ•°æ®
    df_full = df
    
    if viz_type == "æ•£ç‚¹å›¾" and len(metrics) >= 2:
        fig = px.scatter(df_full, x=metrics[0], y=metrics[1], color=dims[0] if dims else None,
                        trendline="ols", title=f"{metrics[0]} vs {metrics[1]}")
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    elif viz_type == "æŠ˜çº¿å›¾" and len(metrics) >= 1:
        fig = px.line(df_full, x=df_full.index, y=metrics[0], color=dims[0] if dims else None, 
                     markers=True, title=f"{metrics[0]} èµ°åŠ¿")
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    elif viz_type == "æŸ±çŠ¶å›¾" and dims and metrics:
        agg_df = df_full.groupby(dims[0])[metrics[0]].sum().reset_index().sort_values(metrics[0], ascending=False).head(20)
        fig = px.bar(agg_df, x=dims[0], y=metrics[0], color=metrics[0], 
                    color_continuous_scale='Blues', title=f"Top 20 {dims[0]}")
        fig.update_layout(height=500, xaxis_tickangle=-45)
        st.plotly_chart(fig, use_container_width=True)
    elif viz_type == "ç®±çº¿å›¾" and dims and metrics:
        fig = px.box(df_full, x=dims[0], y=metrics[0], title=f"{metrics[0]} åˆ†å¸ƒï¼ˆæŒ‰{dims[0]}ï¼‰")
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    elif viz_type == "é¥¼å›¾" and dims and metrics:
        agg_df = df_full.groupby(dims)[metrics].sum().reset_index().sort_values(metrics, ascending=False).head(10)
        fig = px.pie(agg_df, names=dims, values=metrics, title=f"{dims} å æ¯”åˆ†æ", hole=0.4)
        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    elif viz_type == "çƒ­åŠ›å›¾" and len(metrics) >= 2:
        corr = df_full[metrics].corr()
        fig = px.imshow(corr, text_auto=True, aspect="auto", color_continuous_scale='RdBu_r',
                       title="ç›¸å…³æ€§çŸ©é˜µ")
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)

def render_statistics(df, metrics):
    st.markdown('<div class="section-title">ç»Ÿè®¡åˆ†æ</div>', unsafe_allow_html=True)
    
    if not metrics:
        st.info("è¯·é€‰æ‹©åˆ†ææŒ‡æ ‡")
        return
    
    # ç§»é™¤æŒ‡æ ‡æ•°é‡é™åˆ¶ï¼Œä½¿ç”¨å…¨éƒ¨é€‰ä¸­æŒ‡æ ‡
    display_metrics = metrics
    
    stats_module = StatsModule(df)
    
    tab1, tab2, tab3 = st.tabs(["æè¿°ç»Ÿè®¡", "ç›¸å…³æ€§åˆ†æ", "æ­£æ€æ€§æ£€éªŒ"])
    
    with tab1:
        desc = stats_module.descriptive_stats(display_metrics)
        st.dataframe(desc.style.format(smart_format), use_container_width=True)
        
        # é™åˆ¶ç®±çº¿å›¾æ•°é‡é¿å…è¿‡é•¿
        display_for_box = display_metrics[:10] if len(display_metrics) > 10 else display_metrics
        if len(display_metrics) > 10:
            st.caption(f"æŒ‡æ ‡è¾ƒå¤šï¼Œç®±çº¿å›¾ä»…å±•ç¤ºå‰10ä¸ª")
        
        fig = go.Figure()
        for metric in display_for_box:
            fig.add_trace(go.Box(y=df[metric], name=metric))
        fig.update_layout(title="ç®±çº¿å›¾åˆ†å¸ƒ", height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        if len(display_metrics) >= 2:
            corr, fig = stats_module.correlation(display_metrics)
            st.plotly_chart(fig, use_container_width=True)
            st.markdown("**ç›¸å…³æ€§è¯´æ˜ï¼š**")
            st.markdown("- |r| > 0.8: å¼ºç›¸å…³")
            st.markdown("- 0.5 < |r| < 0.8: ä¸­ç­‰ç›¸å…³")
            st.markdown("- |r| < 0.3: å¼±ç›¸å…³")
    
    with tab3:
        results = []
        for col in display_metrics:
            stat, p = stats_module.normality_test(col)
            if stat is not None:
                results.append({
                    'æŒ‡æ ‡': col,
                    'Wç»Ÿè®¡é‡': stat,
                    'På€¼': p,
                    'æ˜¯å¦æ­£æ€': 'æ˜¯' if p > 0.05 else 'å¦',
                    'è§£é‡Š': 'æ•°æ®è¿‘ä¼¼æ­£æ€åˆ†å¸ƒ' if p > 0.05 else 'æ•°æ®åç¦»æ­£æ€åˆ†å¸ƒ'
                })
        if results:
            st.dataframe(pd.DataFrame(results).style.format({
                'Wç»Ÿè®¡é‡': '{:.4f}',
                'På€¼': '{:.4f}'
            }), use_container_width=True)

def render_ml(df, metrics, extra):
    st.markdown('<div class="section-title">æœºå™¨å­¦ä¹ åˆ†æ</div>', unsafe_allow_html=True)
    
    ml = AdvancedMLModule(df)
    task = extra['task']
    algorithm = extra['algorithm']
    params = extra['params']
    
    if st.button("å¼€å§‹è®­ç»ƒ", type="primary", use_container_width=True):
        progress_placeholder = st.empty()
        progress_placeholder.info("æ­£åœ¨è®­ç»ƒæ¨¡å‹...")
        
        if task == "èšç±»åˆ†æ":
            features = metrics if isinstance(metrics, list) else metrics['features']
            if not features or len(features) < 2:
                st.error("è¯·è‡³å°‘é€‰æ‹©2ä¸ªç‰¹å¾")
                return
            fig, stats, score, labeled_data = ml.clustering(features, algorithm, params)
            if fig:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.plotly_chart(fig, use_container_width=True)
                with col2:
                    st.metric("è½®å»“ç³»æ•°", f"{score:.3f}", help="è¶Šæ¥è¿‘1è¶Šå¥½")
                    if algorithm == "KMeans":
                        st.metric("ç°‡æ•°é‡", params['n_clusters'])
                    elif algorithm == "DBSCAN":
                        n_clusters = len(set(stats.index)) - (1 if -1 in stats.index else 0)
                        st.metric("è¯†åˆ«ç°‡æ•°", n_clusters)
                    st.markdown("**å„ç°‡ç»Ÿè®¡:**")
                    st.dataframe(stats, use_container_width=True)
        
        elif task == "å¼‚å¸¸æ£€æµ‹":
            features = metrics if isinstance(metrics, list) else metrics['features']
            fig, count, details = ml.anomaly_detection(features, algorithm, params)
            if fig:
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.plotly_chart(fig, use_container_width=True)
                with col2:
                    total = len(df)
                    pct = count/total*100
                    st.metric("å¼‚å¸¸æ ·æœ¬æ•°", count)
                    st.metric("å¼‚å¸¸æ¯”ä¾‹", f"{pct:.2f}%")
                    st.warning(f"å‘ç° {count} ä¸ªå¼‚å¸¸å€¼") if count > 0 else st.success("æœªå‘ç°æ˜æ˜¾å¼‚å¸¸")
        
        elif task == "å›å½’åˆ†æ":
            target = metrics['target']
            features = metrics['features']
            if not features:
                st.error("è¯·é€‰æ‹©ç‰¹å¾å˜é‡")
                return
            fig, r2, rmse, importance, metrics_dict = ml.regression(target, features, algorithm, params)
            if fig:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.plotly_chart(fig, use_container_width=True)
                with col2:
                    st.metric("RÂ² å†³å®šç³»æ•°", f"{r2:.4f}", help="è¶Šæ¥è¿‘1è¶Šå¥½")
                    st.metric("RMSE", smart_format(rmse), help="å‡æ–¹æ ¹è¯¯å·®")
                    st.metric("MAE", smart_format(metrics_dict['MAE']), help="å¹³å‡ç»å¯¹è¯¯å·®")
                    if importance is not None:
                        st.markdown("**ç‰¹å¾é‡è¦æ€§:**")
                        st.dataframe(importance.head(), use_container_width=True)
        
        elif task == "åˆ†ç±»åˆ†æ":
            target = metrics['target']
            features = metrics['features']
            fig, acc, report, importance, n_classes = ml.classification(target, features, algorithm, params)
            if fig:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.plotly_chart(fig, use_container_width=True)
                with col2:
                    st.metric("å‡†ç¡®ç‡", f"{acc:.2%}")
                    st.markdown("**åˆ†ç±»æŠ¥å‘Š:**")
                    st.dataframe(report.style.format("{:.3f}"), use_container_width=True, height=300)
        
        elif task == "é™ç»´åˆ†æ":
            if algorithm == "PCA":
                features = metrics if isinstance(metrics, list) else metrics['features']
                fig, variance, total_var, loadings = ml.dimension_reduction(features, algorithm, params)
                if fig:
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        st.plotly_chart(fig, use_container_width=True)
                    with col2:
                        st.metric("ç´¯ç§¯è§£é‡Šæ–¹å·®", f"{total_var:.1f}%")
                        st.markdown("**æ–¹å·®è§£é‡Š:**")
                        st.dataframe(variance, use_container_width=True)
                        st.markdown("**æˆåˆ†è½½è·:**")
                        st.dataframe(loadings.round(3), use_container_width=True, height=250)
            elif algorithm == "FeatureImportance":
                target = metrics['target']
                features = metrics['features']
                fig, importance, score, _ = ml.dimension_reduction(features, algorithm, params, target)
                if fig:
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        st.plotly_chart(fig, use_container_width=True)
                    with col2:
                        st.metric("æ¨¡å‹RÂ²", f"{score:.4f}")
                        st.markdown("**é‡è¦æ€§æ’åº:**")
                        st.dataframe(importance.sort_values('é‡è¦æ€§', ascending=False), use_container_width=True)
        
        progress_placeholder.success("åˆ†æå®Œæˆï¼")

def render_forecast(df, date_col, metrics):
    st.markdown('<div class="section-title">æ™ºèƒ½é¢„æµ‹åˆ†æ</div>', unsafe_allow_html=True)
    
    if not date_col:
        st.info("éœ€è¦æ—¶é—´å­—æ®µ")
        return
    
    metric = metrics['metric']
    periods = metrics['periods']
    algorithm = metrics['algorithm']
    
    if st.button("å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True):
        with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {FORECAST_ALGORITHMS[algorithm]['name']} è¿›è¡Œé¢„æµ‹..."):
            forecast_module = AdvancedForecastModule(df)
            fig, info = forecast_module.forecast(date_col, metric, algorithm, periods)
            
            if fig:
                st.plotly_chart(fig, use_container_width=True)
                
                if info:
                    st.markdown("**é¢„æµ‹è¯„ä¼°**")
                    cols = st.columns(len(info))
                    for idx, (key, value) in enumerate(info.items()):
                        with cols[idx]:
                            if isinstance(value, (int, float)):
                                st.metric(key, f"{value:.4f}" if isinstance(value, float) else f"{value:,}")
                            else:
                                st.metric(key, str(value))

def render_cleaning(df):
    st.markdown('<div class="section-title">æ•°æ®æ¸…æ´—</div>', unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        missing = df.isnull().sum().sum()
        st.metric("ç¼ºå¤±å€¼æ€»æ•°", f"{ missing :,}")
    with col2:
        dup = df.duplicated().sum()
        st.metric("é‡å¤è¡Œæ•°", f"{dup:,}")
    with col3:
        st.metric("å†…å­˜å ç”¨", f"{df.memory_usage(deep=True).sum()/1024**2:.2f} MB")
    
    st.markdown("**æ¸…æ´—æ“ä½œ**")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("å¡«å……æ•°å€¼ç¼ºå¤±(å‡å€¼)", use_container_width=True):
            for col in st.session_state.numeric_columns:
                df[col] = df[col].fillna(df[col].mean())
            st.session_state.df = df
            st.success("æ•°å€¼ç¼ºå¤±å·²å¡«å……")
            st.rerun()
    
    with col2:
        if st.button("å¡«å……åˆ†ç±»ç¼ºå¤±(ä¼—æ•°)", use_container_width=True):
            for col in st.session_state.categorical_columns:
                if not df[col].mode().empty:
                    df[col] = df[col].fillna(df[col].mode().iloc[0])
            st.session_state.df = df
            st.success("åˆ†ç±»ç¼ºå¤±å·²å¡«å……")
            st.rerun()
    
    with col3:
        if st.button("åˆ é™¤é‡å¤è¡Œ", use_container_width=True):
            before = len(df)
            df = df.drop_duplicates()
            st.session_state.df = df
            st.success(f"å·²åˆ é™¤ {before - len(df)} è¡Œé‡å¤æ•°æ®")
            st.rerun()
    
    with col4:
        if st.button("é‡ç½®æ‰€æœ‰æ•°æ®", use_container_width=True):
            st.session_state.df = st.session_state.df_original.copy()
            st.success("æ•°æ®å·²é‡ç½®ä¸ºåŸå§‹çŠ¶æ€")
            st.rerun()

def main():
    init_session_state()
    
    with st.sidebar:
        st.markdown("### ğŸ§æ•°æ®åˆ†æå¹³å°")
        st.caption("Advanced Analytics Platform")
        st.divider()
        
        render_upload()
        
        if st.session_state.data_loaded:
            render_data_summary()
            st.divider()
            render_module_buttons()
    
    render_welcome()
    
    if st.session_state.data_loaded:
        module = st.session_state.current_module
        st.markdown("---")
        config_result = render_config(module)
        
        if config_result:
            dims, metrics, date_col, time_range, extra = config_result
            st.markdown("---")
            render_results(module, dims, metrics, date_col, time_range, extra)
    else:
        st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æå–µ~")

if __name__ == "__main__":
    main()
